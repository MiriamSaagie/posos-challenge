{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset # used load data\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers.data.processors.utils import InputExample, InputFeatures\n",
    "from transformers import (AdamW,\n",
    "                          get_linear_schedule_with_warmup,\n",
    "                          get_cosine_with_hard_restarts_schedule_with_warmup)\n",
    "\n",
    "from transformers import (CamembertConfig,\n",
    "                          CamembertForSequenceClassification,\n",
    "                          CamembertTokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data=\"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path_data + \"input_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(path_data + \"output_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(path_data + \"input_test_b1Yip6O.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from glue.py and utils.py\n",
    "\n",
    "class InputExample(object):\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "    \n",
    "class DataProcessor():\n",
    "    \n",
    "    def get_data_examples(self, sentences, labels=None):\n",
    "        examples = []\n",
    "        guid = \"data\"\n",
    "        if labels is None:\n",
    "            for i in range(len(sentences)):\n",
    "                examples.append(InputExample(guid=guid, text_a=sentences[i], text_b=None, label=\"0\"))\n",
    "        else:\n",
    "            for i in range(len(sentences)):\n",
    "                examples.append(InputExample(guid=guid, text_a=sentences[i], text_b=None, label=str(labels[i])))\n",
    "            \n",
    "        return examples\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [str(j) for j in range(51)]\n",
    "\n",
    "    \n",
    "def convert_examples_to_features(examples,\n",
    "                                 tokenizer,\n",
    "                                 max_length=512,\n",
    "                                 label_list=None,\n",
    "                                 pad_on_left=False,\n",
    "                                 pad_token=0,\n",
    "                                 pad_token_segment_id=0,\n",
    "                                 mask_padding_with_zero=True):\n",
    "\n",
    "    processor = DataProcessor()\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            example.text_a,\n",
    "            example.text_b,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n",
    "            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n",
    "        else:\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_ids), max_length)\n",
    "        assert len(attention_mask) == max_length, \"Error with input length {} vs {}\".format(len(attention_mask), max_length)\n",
    "        assert len(token_type_ids) == max_length, \"Error with input length {} vs {}\".format(len(token_type_ids), max_length)\n",
    "        \n",
    "        label = label_map[example.label]\n",
    "        \n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              attention_mask=attention_mask,\n",
    "                              token_type_ids=token_type_ids,\n",
    "                              label=label))\n",
    "\n",
    "    return features\n",
    "\n",
    "def load_and_cache_examples(sentences,\n",
    "                            labels,\n",
    "                            tokenizer, \n",
    "                            max_seq_length,\n",
    "                            label_list):\n",
    " \n",
    "    processor = DataProcessor()\n",
    "    examples = processor.get_data_examples(sentences, labels)\n",
    "\n",
    "    features = convert_examples_to_features(examples,\n",
    "                                            tokenizer,\n",
    "                                            label_list=label_list,\n",
    "                                            max_length=max_seq_length,\n",
    "                                            pad_on_left=False,\n",
    "                                            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                            pad_token_segment_id=0,\n",
    "    )\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, tokenizer, num_train_epochs, train_batch_size, learning_rate, adam_epsilon=1e-8,\n",
    "          logging_steps=None, gradient_accumulation_steps=1, max_grad_norm=1.0, weight_decay=0.0,\n",
    "          warmup_steps=0, save_steps=-1, output_dir=None, evaluate_during_training=False,\n",
    "          seed=None, max_steps=-1, num_cycles=1.0, eval_dataset = None, verbose=0):\n",
    "    \n",
    "    \"\"\" Train the model \"\"\"\n",
    "    \n",
    "    assert not(logging_steps > 0 and eval_dataset is None), \"logging_steps > 0 but no eval_dataset provided\"\n",
    "    \n",
    "    if output_dir is None and save_steps > 0:\n",
    "        output_dir = \"model_\" + str(datetime.datetime.now()).split(\".\")[0].replace(\" \",\"_\") + \"/\"\n",
    "        \n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=train_batch_size)\n",
    "    \n",
    "    if logging_steps is None:\n",
    "        logging_steps = len(train_dataloader) // (gradient_accumulation_steps * 5)\n",
    "        \n",
    "    if max_steps > 0:\n",
    "        t_total = max_steps\n",
    "        num_train_epochs = max_steps // (len(train_dataloader) // gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    \n",
    "    # pas besoin de la partie custom ci-dessous Ã  priori\n",
    "    \n",
    "    #no_decay = ['bias', 'LayerNorm.weight']\n",
    "    #optimizer_grouped_parameters = [\n",
    "    #    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "    #    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    #    ]\n",
    "    \n",
    "    # change l'optimizer pour voir\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon) # optimizer_grouped_parameters\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9) #eps=adam_epsilon , momentum=0.9\n",
    "    #scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer,\n",
    "                                                                   num_warmup_steps=warmup_steps,\n",
    "                                                                   num_training_steps=t_total,\n",
    "                                                                   num_cycles=num_cycles)\n",
    "    #for i, tensor in enumerate(model.parameters()):\n",
    "    #    if i > 1:\n",
    "    #        tensor.requires_grad = False\n",
    "\n",
    "    # Train!\n",
    "    print(\"***** Running training *****\")\n",
    "    print(\"  Num examples = %d\" % len(train_dataset))\n",
    "    print(\"  Num Epochs = %d\" % num_train_epochs)\n",
    "    print(\" Batch size = %d\" % train_batch_size)\n",
    "    print(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\" %\n",
    "                   train_batch_size * gradient_accumulation_steps)\n",
    "    print(\"  Gradient Accumulation steps = %d\" % gradient_accumulation_steps)\n",
    "    print(\"  Total optimization steps = %d\" % t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(num_train_epochs), desc=\"Epoch\")\n",
    "    if seed is not None:\n",
    "        set_seed(seed)\n",
    "        \n",
    "    for epoch, _ in enumerate(train_iterator):\n",
    "        # print(\"Epoch %d / %d\" % (epoch, num_train_epochs))\n",
    "        epoch_iterator = train_dataloader\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[3]}\n",
    "            inputs['token_type_ids'] = batch[2] #or None\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            #print(outputs)\n",
    "            #print(outputs[0].size())\n",
    "            #print(outputs[1].size())\n",
    "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
    "            #print(loss)\n",
    "            \n",
    "            if gradient_accumulation_steps > 1:\n",
    "                loss = loss / gradient_accumulation_steps\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if verbose > 0:\n",
    "                print(\"lr:\",scheduler.get_lr()[0], \"loss:\", loss.item())\n",
    "                \n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if logging_steps > 0 and global_step % logging_steps == 0:\n",
    "                    if verbose > 0:\n",
    "                        print(\"\\nEval\")\n",
    "                    # Log metrics\n",
    "                    dict_print = {'step':global_step,\n",
    "                                  'lr': scheduler.get_lr()[0],\n",
    "                                  'tr_loss': (tr_loss - logging_loss)/logging_steps}\n",
    "                    if evaluate_during_training:\n",
    "                        results = evaluate(model=model, eval_dataset=eval_dataset,\n",
    "                                           tokenizer=tokenizer, eval_output_dir=output_dir,\n",
    "                                           verbose=verbose)\n",
    "                        for key, value in results.items():\n",
    "                            dict_print['eval_{}'.format(key)] = value\n",
    "                    print(dict_print)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if save_steps > 0 and global_step % save_steps == 0:\n",
    "                    # Save model checkpoint\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    save_model_dir = os.path.join(output_dir, 'checkpoint-{}'.format(global_step))\n",
    "                    os.makedirs(save_model_dir)\n",
    "                    model.save_pretrained(save_model_dir)\n",
    "                    #torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
    "                    print(\"Saving model checkpoint to %s\" % save_model_dir)\n",
    "\n",
    "            if max_steps > 0 and global_step > max_steps:\n",
    "                #epoch_iterator.close() #deleted since no tqdm anymore\n",
    "                break\n",
    "                \n",
    "        if max_steps > 0 and global_step > max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if global_step == 0:\n",
    "        global_step= 1\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_dataset, tokenizer, eval_batch_size=8, prefix=\"\", eval_output_dir=None,\n",
    "             verbose=1):\n",
    "        \n",
    "    eval_batch_size = eval_batch_size\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "    \n",
    "    # Eval!\n",
    "    if verbose > 0:\n",
    "        print(\"***** Running evaluation {} *****\".format(prefix))\n",
    "        print(\"  Num examples = %d\", len(eval_dataset))\n",
    "        print(\"  Batch size = %d\", eval_batch_size)\n",
    "        \n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    iterator = tqdm(eval_dataloader, desc=\"Evaluating\") if verbose > 0 else eval_dataloader\n",
    "    \n",
    "    for batch in iterator:\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[3]}\n",
    "            inputs['token_type_ids'] = batch[2] #or None\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    preds_class = np.argmax(preds, axis=1)\n",
    "    acc = accuracy_score(out_label_ids, preds_class)\n",
    "    \n",
    "    result = {\"val_loss\": eval_loss, \"val_acc\" : acc}\n",
    "    #results.update(result)\n",
    "\n",
    "    if eval_output_dir is not None:\n",
    "        if not os.path.exists(eval_output_dir):\n",
    "            os.makedirs(eval_output_dir)\n",
    "        \n",
    "        output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
    "        with open(output_eval_file, \"a\") as writer:\n",
    "            writer.write(\"***** Eval results {} *****\".format(prefix))\n",
    "            for key in sorted(result.keys()):\n",
    "                writer.write(\"  %s = %s\" % (key, str(result[key])))\n",
    "            writer.write(\"\\n\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset, batch_size, verbose=1):\n",
    "    \n",
    "    # Note that DistributedSampler samples randomly\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "    # Eval!\n",
    "    if verbose > 0:\n",
    "        print(\"***** Running prediction *****\")\n",
    "        print(\"  Num examples = %d\", len(dataset))\n",
    "        print(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "    loss = 0.0\n",
    "    nb_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    iterator = tqdm(dataloader, desc=\"Predict\") if verbose > 0 else dataloader\n",
    "    \n",
    "    for batch in iterator:\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[3]}\n",
    "            inputs['token_type_ids'] = batch[2] #or None\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "            loss += tmp_eval_loss.mean().item()\n",
    "        nb_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    loss = loss / nb_steps\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=51\n",
    "model_name=\"camembert-base\"\n",
    "\n",
    "config = CamembertConfig.from_pretrained(model_name,\n",
    "                                         num_labels=num_labels,\n",
    "                                         finetuning_task=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained(model_name,\n",
    "                                               do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CamembertForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_val, labels_train, labels_val = train_test_split(df_train[\"question\"].values,\n",
    "                                                                            df_labels[\"intention\"].values,\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example 0\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_and_cache_examples(sentences=sentences_train,\n",
    "                                  labels=labels_train,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  max_seq_length = 128,\n",
    "                                  label_list = [str(j) for j in range(num_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example 0\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = load_and_cache_examples(sentences=sentences_val,\n",
    "                                  labels=labels_val,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  max_seq_length = 128,\n",
    "                                  label_list = [str(j) for j in range(num_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 6422\n",
      "  Num Epochs = 1\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e564615b64e4bb3a4588b65edc0d4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initialâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Eval\n",
      "{'step': 2, 'lr': 2.2500000000000015e-05, 'tr_loss': 3.9270644187927246, 'eval_val_loss': 3.9023621568632363, 'eval_val_acc': 0.02054794520547945}\n",
      "\n",
      "\n",
      "Eval\n",
      "{'step': 4, 'lr': 0.0, 'tr_loss': 3.9058990478515625, 'eval_val_loss': 3.8899942262848812, 'eval_val_acc': 0.08468244084682441}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 3.9164817333221436)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model=model, train_dataset=train_dataset, tokenizer=tokenizer, train_batch_size=32,\n",
    "      learning_rate=3e-5, num_train_epochs=10, evaluate_during_training=True, logging_steps=2,\n",
    "      max_grad_norm=1.0, save_steps=-1, num_cycles=5.0, max_steps=3, eval_dataset=eval_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pred on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CamembertForSequenceClassification.from_pretrained(\"model_2019-12-08_14:59:37/checkpoint-400/checkpoint-800/checkpoint-1200/\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features from cached file data/cached_test_128\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 1606\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1f31e9dc9541e1a846ff11112f9400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=201, style=ProgressStyle(description_width='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 1.5273962446409672, 'val_acc': 0.6749688667496887}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, eval_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example 0\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_and_cache_examples(sentences=df_test[\"question\"],\n",
    "                                  labels=None,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  max_seq_length = 128,\n",
    "                                  label_list = [str(j) for j in range(51)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4475a52058e44f488e29bd2cf62a97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='iniâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds_test = predict(model=model,\n",
    "                     dataset=test_dataset,\n",
    "                     batch_size = 8)\n",
    "preds_class_test = np.argmax(preds_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"ID\": df_test[\"ID\"].values,  \"intention\": preds_class_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8028</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8029</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8030</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8031</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8032</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  intention\n",
       "0  8028         32\n",
       "1  8029         32\n",
       "2  8030         32\n",
       "3  8031         31\n",
       "4  8032         44"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub/sub0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kfold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_and_cache_examples(sentences=df_test[\"question\"].values,\n",
    "                                  labels=None,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  max_seq_length = 128,\n",
    "                                  label_list = [str(j) for j in range(51)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 :\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 7225\n",
      "  Num Epochs = 12\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379514d2d1764df5b48ea6ea3c3687cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 200, 'lr': 1.769593682237682e-05, 'tr_loss': 3.207913815975189, 'eval_val_loss': 2.6223922731852767, 'eval_val_acc': 0.37982565379825656}\n",
      "{'step': 400, 'lr': 9.690767133662976e-07, 'tr_loss': 2.5525126135349274, 'eval_val_loss': 2.3774816759742134, 'eval_val_acc': 0.5193026151930261}\n",
      "{'step': 600, 'lr': 2.2739467854427512e-05, 'tr_loss': 2.306243928074837, 'eval_val_loss': 1.9948222890938863, 'eval_val_acc': 0.6064757160647571}\n",
      "{'step': 800, 'lr': 3.7510922299466767e-06, 'tr_loss': 1.8657918626070022, 'eval_val_loss': 1.7703141770740547, 'eval_val_acc': 0.6438356164383562}\n",
      "{'step': 1000, 'lr': 2.6782980476935185e-05, 'tr_loss': 1.7124177992343903, 'eval_val_loss': 1.6429045589843598, 'eval_val_acc': 0.6537982565379825}\n",
      "{'step': 1200, 'lr': 7.986581689295574e-06, 'tr_loss': 1.4640957689285279, 'eval_val_loss': 1.4495849482493826, 'eval_val_acc': 0.6948941469489415}\n",
      "{'step': 1400, 'lr': 2.930401150020983e-05, 'tr_loss': 1.2919925141334534, 'eval_val_loss': 1.3832152583221398, 'eval_val_acc': 0.6924034869240349}\n",
      "{'step': 1600, 'lr': 1.3128276530777865e-05, 'tr_loss': 1.1804899773001671, 'eval_val_loss': 1.2808475990106565, 'eval_val_acc': 0.7198007471980075}\n",
      "{'step': 1800, 'lr': 2.3182070192458437e-08, 'tr_loss': 1.0100990748405456, 'eval_val_loss': 1.2263533973162717, 'eval_val_acc': 0.7272727272727273}\n",
      "{'step': 2000, 'lr': 1.851181718931142e-05, 'tr_loss': 0.9496048055589199, 'eval_val_loss': 1.182128647176346, 'eval_val_acc': 0.7285180572851806}\n",
      "{'step': 2200, 'lr': 1.2855337067418576e-06, 'tr_loss': 0.8029603470861911, 'eval_val_loss': 1.1171627369257484, 'eval_val_acc': 0.7521793275217933}\n",
      "{'step': 2400, 'lr': 2.344159514654345e-05, 'tr_loss': 0.783771313726902, 'eval_val_loss': 1.1004292504622204, 'eval_val_acc': 0.763387297633873}\n",
      "{'step': 2600, 'lr': 4.319934666097069e-06, 'tr_loss': 0.656023850440979, 'eval_val_loss': 1.0519690275339797, 'eval_val_acc': 0.7733499377334994}\n",
      "\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 803\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85cc9662f5b43b0bcd3c73da6156090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=101, style=ProgressStyle(description_width='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final eval: {'val_loss': 1.0426002315217906, 'val_acc': 0.7733499377334994}\n",
      "***** Running prediction *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822e3f3ab004403ebc533444dc858dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='iniâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 :\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 7225\n",
      "  Num Epochs = 12\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3e5cbae7c8487a835d016c107ca98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 200, 'lr': 1.769593682237682e-05, 'tr_loss': 3.236713910102844, 'eval_val_loss': 2.7101347942163447, 'eval_val_acc': 0.37982565379825656}\n",
      "{'step': 400, 'lr': 9.690767133662976e-07, 'tr_loss': 2.5572206300497053, 'eval_val_loss': 2.429888894062231, 'eval_val_acc': 0.48318804483188044}\n",
      "{'step': 600, 'lr': 2.2739467854427512e-05, 'tr_loss': 2.2947192072868345, 'eval_val_loss': 2.0039674887562744, 'eval_val_acc': 0.6201743462017435}\n",
      "{'step': 800, 'lr': 3.7510922299466767e-06, 'tr_loss': 1.8716538316011428, 'eval_val_loss': 1.7796642632767705, 'eval_val_acc': 0.6662515566625156}\n",
      "{'step': 1000, 'lr': 2.6782980476935185e-05, 'tr_loss': 1.7478939694166185, 'eval_val_loss': 1.6314445828447248, 'eval_val_acc': 0.6787048567870486}\n",
      "{'step': 1200, 'lr': 7.986581689295574e-06, 'tr_loss': 1.4192626783251763, 'eval_val_loss': 1.4512522772397145, 'eval_val_acc': 0.6924034869240349}\n",
      "{'step': 1400, 'lr': 2.930401150020983e-05, 'tr_loss': 1.296587422788143, 'eval_val_loss': 1.388723781498352, 'eval_val_acc': 0.7222914072229141}\n",
      "{'step': 1600, 'lr': 1.3128276530777865e-05, 'tr_loss': 1.1451042240858078, 'eval_val_loss': 1.260278200454051, 'eval_val_acc': 0.7434620174346201}\n",
      "{'step': 1800, 'lr': 2.3182070192458437e-08, 'tr_loss': 0.9712993781268596, 'eval_val_loss': 1.221738568036863, 'eval_val_acc': 0.7521793275217933}\n",
      "{'step': 2000, 'lr': 1.851181718931142e-05, 'tr_loss': 0.9097282488644123, 'eval_val_loss': 1.1624272161781197, 'eval_val_acc': 0.7584059775840598}\n",
      "{'step': 2200, 'lr': 1.2855337067418576e-06, 'tr_loss': 0.7657484260201454, 'eval_val_loss': 1.1372798527821455, 'eval_val_acc': 0.7584059775840598}\n",
      "{'step': 2400, 'lr': 2.344159514654345e-05, 'tr_loss': 0.714546964019537, 'eval_val_loss': 1.1133175099840258, 'eval_val_acc': 0.7621419676214197}\n",
      "{'step': 2600, 'lr': 4.319934666097069e-06, 'tr_loss': 0.6351496802270412, 'eval_val_loss': 1.0615124513607215, 'eval_val_acc': 0.7783312577833126}\n",
      "\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 803\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef9081099ea4dee8b5edc6d9f16ab14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=101, style=ProgressStyle(description_width='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final eval: {'val_loss': 1.0667237745653284, 'val_acc': 0.7708592777085927}\n",
      "***** Running prediction *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffccac7df994335b06f3f7437207621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='iniâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 :\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 7225\n",
      "  Num Epochs = 12\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9b2eb69e954904923037e8b80db2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 200, 'lr': 1.769593682237682e-05, 'tr_loss': 3.2343286967277525, 'eval_val_loss': 2.7133586253270066, 'eval_val_acc': 0.38854296388542964}\n",
      "{'step': 400, 'lr': 9.690767133662976e-07, 'tr_loss': 2.5629944974184036, 'eval_val_loss': 2.440503350578912, 'eval_val_acc': 0.4919053549190536}\n",
      "{'step': 600, 'lr': 2.2739467854427512e-05, 'tr_loss': 2.3523574167490007, 'eval_val_loss': 2.04425308019808, 'eval_val_acc': 0.6027397260273972}\n",
      "{'step': 800, 'lr': 3.7510922299466767e-06, 'tr_loss': 1.8642867535352707, 'eval_val_loss': 1.7987645970712793, 'eval_val_acc': 0.6537982565379825}\n",
      "{'step': 1000, 'lr': 2.6782980476935185e-05, 'tr_loss': 1.72810256421566, 'eval_val_loss': 1.6514739164031378, 'eval_val_acc': 0.6612702366127023}\n",
      "{'step': 1200, 'lr': 7.986581689295574e-06, 'tr_loss': 1.471124939918518, 'eval_val_loss': 1.467030827656831, 'eval_val_acc': 0.6986301369863014}\n",
      "{'step': 1400, 'lr': 2.930401150020983e-05, 'tr_loss': 1.2872735363245011, 'eval_val_loss': 1.4325605061384712, 'eval_val_acc': 0.6924034869240349}\n",
      "{'step': 1600, 'lr': 1.3128276530777865e-05, 'tr_loss': 1.17210823148489, 'eval_val_loss': 1.2917020943495308, 'eval_val_acc': 0.7073474470734745}\n",
      "{'step': 1800, 'lr': 2.3182070192458437e-08, 'tr_loss': 0.9970666348934174, 'eval_val_loss': 1.255297354542383, 'eval_val_acc': 0.7247820672478207}\n",
      "{'step': 2000, 'lr': 1.851181718931142e-05, 'tr_loss': 0.9250655090808868, 'eval_val_loss': 1.228163621508249, 'eval_val_acc': 0.7347447073474471}\n",
      "{'step': 2200, 'lr': 1.2855337067418576e-06, 'tr_loss': 0.7985275167226792, 'eval_val_loss': 1.1515066133867395, 'eval_val_acc': 0.7310087173100872}\n",
      "{'step': 2400, 'lr': 2.344159514654345e-05, 'tr_loss': 0.7622015370428562, 'eval_val_loss': 1.149330448396135, 'eval_val_acc': 0.7397260273972602}\n",
      "{'step': 2600, 'lr': 4.319934666097069e-06, 'tr_loss': 0.6366784828901291, 'eval_val_loss': 1.0809540443196155, 'eval_val_acc': 0.7683686176836861}\n",
      "\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 803\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1623729922e431bb3fe969d0a72e165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=101, style=ProgressStyle(description_width='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final eval: {'val_loss': 1.0775624789518885, 'val_acc': 0.7671232876712328}\n",
      "***** Running prediction *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277446d70ba94356a36fe02c6a7f8e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='iniâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 :\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 7225\n",
      "  Num Epochs = 12\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee383eef40e49e894ad1a905c742d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 200, 'lr': 1.769593682237682e-05, 'tr_loss': 3.2390654289722445, 'eval_val_loss': 2.6826166032564522, 'eval_val_acc': 0.40099626400996263}\n",
      "{'step': 400, 'lr': 9.690767133662976e-07, 'tr_loss': 2.5834085005521774, 'eval_val_loss': 2.438758894948676, 'eval_val_acc': 0.48816936488169366}\n",
      "{'step': 600, 'lr': 2.2739467854427512e-05, 'tr_loss': 2.3278399389982223, 'eval_val_loss': 2.0515148710496356, 'eval_val_acc': 0.5753424657534246}\n",
      "{'step': 800, 'lr': 3.7510922299466767e-06, 'tr_loss': 1.9056653410196305, 'eval_val_loss': 1.833842917834178, 'eval_val_acc': 0.6114570361145704}\n",
      "{'step': 1000, 'lr': 2.6782980476935185e-05, 'tr_loss': 1.7410446274280549, 'eval_val_loss': 1.718252675958199, 'eval_val_acc': 0.6027397260273972}\n",
      "{'step': 1200, 'lr': 7.986581689295574e-06, 'tr_loss': 1.4774141868948936, 'eval_val_loss': 1.549132097770672, 'eval_val_acc': 0.6662515566625156}\n",
      "{'step': 1400, 'lr': 2.930401150020983e-05, 'tr_loss': 1.3052476313710213, 'eval_val_loss': 1.4826718577654054, 'eval_val_acc': 0.6836861768368617}\n",
      "{'step': 1600, 'lr': 1.3128276530777865e-05, 'tr_loss': 1.2040205299854279, 'eval_val_loss': 1.3571992687659689, 'eval_val_acc': 0.6986301369863014}\n",
      "{'step': 1800, 'lr': 2.3182070192458437e-08, 'tr_loss': 1.0187616282701493, 'eval_val_loss': 1.318938421140803, 'eval_val_acc': 0.7198007471980075}\n",
      "{'step': 2000, 'lr': 1.851181718931142e-05, 'tr_loss': 0.9471620947122574, 'eval_val_loss': 1.2552753645594756, 'eval_val_acc': 0.7272727272727273}\n",
      "{'step': 2200, 'lr': 1.2855337067418576e-06, 'tr_loss': 0.7982275973260403, 'eval_val_loss': 1.2021494274682338, 'eval_val_acc': 0.7409713574097135}\n",
      "{'step': 2400, 'lr': 2.344159514654345e-05, 'tr_loss': 0.7637372855842114, 'eval_val_loss': 1.1907891648830753, 'eval_val_acc': 0.7434620174346201}\n",
      "{'step': 2600, 'lr': 4.319934666097069e-06, 'tr_loss': 0.6477089489996434, 'eval_val_loss': 1.1285946006231968, 'eval_val_acc': 0.7422166874221668}\n",
      "\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 803\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9036ce6bb76f496da822a50a772723f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=101, style=ProgressStyle(description_width='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final eval: {'val_loss': 1.1208856657590016, 'val_acc': 0.7409713574097135}\n",
      "***** Running prediction *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af55aa5b2da74a94a120d43593c07fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='iniâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 :\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 7225\n",
      "  Num Epochs = 12\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff6007109f24788bd40c894d85c0936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 200, 'lr': 1.769593682237682e-05, 'tr_loss': 3.230266991853714, 'eval_val_loss': 2.7203104555016697, 'eval_val_acc': 0.3574097135740971}\n",
      "{'step': 400, 'lr': 9.690767133662976e-07, 'tr_loss': 2.5798735290765764, 'eval_val_loss': 2.4605194755119855, 'eval_val_acc': 0.48816936488169366}\n",
      "{'step': 600, 'lr': 2.2739467854427512e-05, 'tr_loss': 2.334317823648453, 'eval_val_loss': 2.062535488959586, 'eval_val_acc': 0.5678704856787049}\n",
      "{'step': 800, 'lr': 3.7510922299466767e-06, 'tr_loss': 1.917541393637657, 'eval_val_loss': 1.8458638515802894, 'eval_val_acc': 0.6201743462017435}\n",
      "{'step': 1000, 'lr': 2.6782980476935185e-05, 'tr_loss': 1.710310961008072, 'eval_val_loss': 1.6983230721832503, 'eval_val_acc': 0.6475716064757161}\n",
      "{'step': 1200, 'lr': 7.986581689295574e-06, 'tr_loss': 1.4871706792712212, 'eval_val_loss': 1.5050200728496703, 'eval_val_acc': 0.6874221668742216}\n",
      "{'step': 1400, 'lr': 2.930401150020983e-05, 'tr_loss': 1.3205339235067368, 'eval_val_loss': 1.4560404850704836, 'eval_val_acc': 0.6948941469489415}\n",
      "{'step': 1600, 'lr': 1.3128276530777865e-05, 'tr_loss': 1.1510612154006958, 'eval_val_loss': 1.3316312627036972, 'eval_val_acc': 0.7148194271481942}\n",
      "{'step': 1800, 'lr': 2.3182070192458437e-08, 'tr_loss': 0.9844898110628129, 'eval_val_loss': 1.281434263628308, 'eval_val_acc': 0.7222914072229141}\n",
      "{'step': 2000, 'lr': 1.851181718931142e-05, 'tr_loss': 0.9173762784898281, 'eval_val_loss': 1.203313523885047, 'eval_val_acc': 0.7285180572851806}\n",
      "{'step': 2200, 'lr': 1.2855337067418576e-06, 'tr_loss': 0.7999245814979077, 'eval_val_loss': 1.1471787366536583, 'eval_val_acc': 0.7434620174346201}\n",
      "{'step': 2400, 'lr': 2.344159514654345e-05, 'tr_loss': 0.7350942577421665, 'eval_val_loss': 1.1253601067727155, 'eval_val_acc': 0.7409713574097135}\n",
      "{'step': 2600, 'lr': 4.319934666097069e-06, 'tr_loss': 0.631235929876566, 'eval_val_loss': 1.0883647976535382, 'eval_val_acc': 0.7596513075965131}\n",
      "\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 803\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2619a8cfa149ab87ade24ff4b717ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=101, style=ProgressStyle(description_width='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final eval: {'val_loss': 1.0916563573450144, 'val_acc': 0.763387297633873}\n",
      "***** Running prediction *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00401b3186714d4d91ca989190d8f77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='iniâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5 :\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 7225\n",
      "  Num Epochs = 12\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff8654a0ffc49898c2830439cb1bb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 200, 'lr': 1.769593682237682e-05, 'tr_loss': 3.2582884442806246, 'eval_val_loss': 2.754422467533905, 'eval_val_acc': 0.36239103362391034}\n",
      "{'step': 400, 'lr': 9.690767133662976e-07, 'tr_loss': 2.6131298220157624, 'eval_val_loss': 2.4834123342344077, 'eval_val_acc': 0.4943960149439601}\n",
      "{'step': 600, 'lr': 2.2739467854427512e-05, 'tr_loss': 2.346120905280113, 'eval_val_loss': 2.118796208117268, 'eval_val_acc': 0.564134495641345}\n",
      "{'step': 800, 'lr': 3.7510922299466767e-06, 'tr_loss': 1.9380844485759736, 'eval_val_loss': 1.875553026647851, 'eval_val_acc': 0.6114570361145704}\n",
      "{'step': 1000, 'lr': 2.6782980476935185e-05, 'tr_loss': 1.7773268437385559, 'eval_val_loss': 1.7141866554128062, 'eval_val_acc': 0.6400996264009963}\n",
      "{'step': 1200, 'lr': 7.986581689295574e-06, 'tr_loss': 1.4816854250431062, 'eval_val_loss': 1.5378368089694787, 'eval_val_acc': 0.6724782067247821}\n",
      "{'step': 1400, 'lr': 2.930401150020983e-05, 'tr_loss': 1.3229927721619605, 'eval_val_loss': 1.492951993895049, 'eval_val_acc': 0.6861768368617683}\n",
      "{'step': 1600, 'lr': 1.3128276530777865e-05, 'tr_loss': 1.2096424898505211, 'eval_val_loss': 1.3455984796037768, 'eval_val_acc': 0.7085927770859277}\n",
      "{'step': 1800, 'lr': 2.3182070192458437e-08, 'tr_loss': 1.0207867434620856, 'eval_val_loss': 1.2998775816199803, 'eval_val_acc': 0.7160647571606475}\n",
      "{'step': 2000, 'lr': 1.851181718931142e-05, 'tr_loss': 0.9531258374452591, 'eval_val_loss': 1.2423571410155532, 'eval_val_acc': 0.7222914072229141}\n",
      "{'step': 2200, 'lr': 1.2855337067418576e-06, 'tr_loss': 0.8022571790218354, 'eval_val_loss': 1.1865614537555393, 'eval_val_acc': 0.7272727272727273}\n",
      "{'step': 2400, 'lr': 2.344159514654345e-05, 'tr_loss': 0.7453095696866512, 'eval_val_loss': 1.1675986671211696, 'eval_val_acc': 0.7285180572851806}\n",
      "{'step': 2600, 'lr': 4.319934666097069e-06, 'tr_loss': 0.663769681751728, 'eval_val_loss': 1.1253668114100353, 'eval_val_acc': 0.7409713574097135}\n",
      "\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 803\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ba9163d3ae424a905216fe65fed6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=101, style=ProgressStyle(description_width='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final eval: {'val_loss': 1.1208602063136526, 'val_acc': 0.7459526774595268}\n",
      "***** Running prediction *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da194a26d7ec4165ad0f1cb434e70a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='iniâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 6 :\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 7225\n",
      "  Num Epochs = 12\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348f1d37fa244ed78f21b31f8f12de7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 200, 'lr': 1.769593682237682e-05, 'tr_loss': 3.183963282108307, 'eval_val_loss': 2.638268824851159, 'eval_val_acc': 0.43462017434620176}\n",
      "{'step': 400, 'lr': 9.690767133662976e-07, 'tr_loss': 2.5348266839981077, 'eval_val_loss': 2.3853838549982203, 'eval_val_acc': 0.5342465753424658}\n",
      "{'step': 600, 'lr': 2.2739467854427512e-05, 'tr_loss': 2.2848053365945815, 'eval_val_loss': 1.974329413753925, 'eval_val_acc': 0.6376089663760897}\n",
      "{'step': 800, 'lr': 3.7510922299466767e-06, 'tr_loss': 1.8566222602128983, 'eval_val_loss': 1.7601390982618426, 'eval_val_acc': 0.6811955168119551}\n",
      "{'step': 1000, 'lr': 2.6782980476935185e-05, 'tr_loss': 1.6883805245161057, 'eval_val_loss': 1.6212109070603211, 'eval_val_acc': 0.6936488169364882}\n",
      "{'step': 1200, 'lr': 7.986581689295574e-06, 'tr_loss': 1.4503039991855622, 'eval_val_loss': 1.429327648464996, 'eval_val_acc': 0.7210460772104608}\n",
      "{'step': 1400, 'lr': 2.930401150020983e-05, 'tr_loss': 1.2772510746121406, 'eval_val_loss': 1.3548824580589143, 'eval_val_acc': 0.7110834371108343}\n",
      "{'step': 1600, 'lr': 1.3128276530777865e-05, 'tr_loss': 1.144770429134369, 'eval_val_loss': 1.258522063788801, 'eval_val_acc': 0.7347447073474471}\n",
      "{'step': 1800, 'lr': 2.3182070192458437e-08, 'tr_loss': 0.9942598846554757, 'eval_val_loss': 1.220152764627249, 'eval_val_acc': 0.7359900373599004}\n",
      "{'step': 2000, 'lr': 1.851181718931142e-05, 'tr_loss': 0.9233821235597134, 'eval_val_loss': 1.1193825478600983, 'eval_val_acc': 0.7559153175591532}\n",
      "{'step': 2200, 'lr': 1.2855337067418576e-06, 'tr_loss': 0.7646545426547527, 'eval_val_loss': 1.0918398785709154, 'eval_val_acc': 0.7671232876712328}\n",
      "{'step': 2400, 'lr': 2.344159514654345e-05, 'tr_loss': 0.7354181031882763, 'eval_val_loss': 1.065677514760801, 'eval_val_acc': 0.7770859277708593}\n",
      "{'step': 2600, 'lr': 4.319934666097069e-06, 'tr_loss': 0.621963469684124, 'eval_val_loss': 1.0392576206733686, 'eval_val_acc': 0.772104607721046}\n",
      "\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 803\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45b89a8369f433993cd2d492c2d20ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=101, style=ProgressStyle(description_width='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final eval: {'val_loss': 1.0276066359907094, 'val_acc': 0.7820672478206725}\n",
      "***** Running prediction *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff208b87180456c88228e8a603c2f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='iniâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 7 :\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 7225\n",
      "  Num Epochs = 12\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5bb399c5ec44f0980523701d6c32a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 200, 'lr': 1.769593682237682e-05, 'tr_loss': 3.244401652812958, 'eval_val_loss': 2.7140135517214783, 'eval_val_acc': 0.32378580323785805}\n",
      "{'step': 400, 'lr': 9.690767133662976e-07, 'tr_loss': 2.60562657892704, 'eval_val_loss': 2.473530330280266, 'eval_val_acc': 0.49813200498132004}\n",
      "{'step': 600, 'lr': 2.2739467854427512e-05, 'tr_loss': 2.352717698216438, 'eval_val_loss': 2.114164478708022, 'eval_val_acc': 0.6201743462017435}\n",
      "{'step': 800, 'lr': 3.7510922299466767e-06, 'tr_loss': 1.9518596416711806, 'eval_val_loss': 1.8597267936952044, 'eval_val_acc': 0.660024906600249}\n",
      "{'step': 1000, 'lr': 2.6782980476935185e-05, 'tr_loss': 1.777642201781273, 'eval_val_loss': 1.6809911748560349, 'eval_val_acc': 0.6824408468244084}\n",
      "{'step': 1200, 'lr': 7.986581689295574e-06, 'tr_loss': 1.5034914553165435, 'eval_val_loss': 1.5090378806142524, 'eval_val_acc': 0.6961394769613948}\n",
      "{'step': 1400, 'lr': 2.930401150020983e-05, 'tr_loss': 1.3336021095514297, 'eval_val_loss': 1.4312693615361016, 'eval_val_acc': 0.7110834371108343}\n",
      "{'step': 1600, 'lr': 1.3128276530777865e-05, 'tr_loss': 1.1958303609490395, 'eval_val_loss': 1.2862369969929799, 'eval_val_acc': 0.7409713574097135}\n",
      "{'step': 1800, 'lr': 2.3182070192458437e-08, 'tr_loss': 1.0209269078075887, 'eval_val_loss': 1.2420848292289395, 'eval_val_acc': 0.7459526774595268}\n",
      "{'step': 2000, 'lr': 1.851181718931142e-05, 'tr_loss': 0.9548484548926354, 'eval_val_loss': 1.1765184012970122, 'eval_val_acc': 0.7484433374844334}\n",
      "{'step': 2200, 'lr': 1.2855337067418576e-06, 'tr_loss': 0.8354085095226764, 'eval_val_loss': 1.1173797698304204, 'eval_val_acc': 0.7596513075965131}\n",
      "{'step': 2400, 'lr': 2.344159514654345e-05, 'tr_loss': 0.7702505154907704, 'eval_val_loss': 1.1088532649054386, 'eval_val_acc': 0.7559153175591532}\n",
      "{'step': 2600, 'lr': 4.319934666097069e-06, 'tr_loss': 0.6721640373021365, 'eval_val_loss': 1.0710603600681419, 'eval_val_acc': 0.7683686176836861}\n",
      "\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 803\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9e5d7409764b9d83683aa928117ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=101, style=ProgressStyle(description_width='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final eval: {'val_loss': 1.0618431190452953, 'val_acc': 0.7708592777085927}\n",
      "***** Running prediction *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cc7dd9aaf34aa4be70500663d2dbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='iniâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 8 :\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 7226\n",
      "  Num Epochs = 12\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd47edeb0dd42f199f37d28533e2ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 200, 'lr': 1.769593682237682e-05, 'tr_loss': 3.2077666008472443, 'eval_val_loss': 2.7172064757583163, 'eval_val_acc': 0.40648379052369077}\n",
      "{'step': 400, 'lr': 9.690767133662976e-07, 'tr_loss': 2.5505060148239136, 'eval_val_loss': 2.4731061989718146, 'eval_val_acc': 0.5124688279301746}\n",
      "{'step': 600, 'lr': 2.2739467854427512e-05, 'tr_loss': 2.316533092260361, 'eval_val_loss': 2.066327992052135, 'eval_val_acc': 0.5972568578553616}\n",
      "{'step': 800, 'lr': 3.7510922299466767e-06, 'tr_loss': 1.8514123624563217, 'eval_val_loss': 1.8299753335442874, 'eval_val_acc': 0.6458852867830424}\n",
      "{'step': 1000, 'lr': 2.6782980476935185e-05, 'tr_loss': 1.7192760223150254, 'eval_val_loss': 1.680228611030201, 'eval_val_acc': 0.6471321695760599}\n",
      "{'step': 1200, 'lr': 7.986581689295574e-06, 'tr_loss': 1.4626756805181502, 'eval_val_loss': 1.4842678650771037, 'eval_val_acc': 0.6907730673316709}\n",
      "{'step': 1400, 'lr': 2.930401150020983e-05, 'tr_loss': 1.2608507728576661, 'eval_val_loss': 1.442084944189185, 'eval_val_acc': 0.6970074812967582}\n",
      "{'step': 1600, 'lr': 1.3128276530777865e-05, 'tr_loss': 1.152700155377388, 'eval_val_loss': 1.2982359026918318, 'eval_val_acc': 0.7119700748129676}\n",
      "{'step': 1800, 'lr': 2.3182070192458437e-08, 'tr_loss': 0.9774947100877762, 'eval_val_loss': 1.2622679651963828, 'eval_val_acc': 0.7044887780548629}\n",
      "{'step': 2000, 'lr': 1.851181718931142e-05, 'tr_loss': 0.9305512972176075, 'eval_val_loss': 1.2057881715274092, 'eval_val_acc': 0.7169576059850374}\n",
      "{'step': 2200, 'lr': 1.2855337067418576e-06, 'tr_loss': 0.7843483777344227, 'eval_val_loss': 1.1542858623041965, 'eval_val_acc': 0.7231920199501247}\n",
      "{'step': 2400, 'lr': 2.344159514654345e-05, 'tr_loss': 0.7102423238754273, 'eval_val_loss': 1.163489924504025, 'eval_val_acc': 0.7281795511221946}\n",
      "{'step': 2600, 'lr': 4.319934666097069e-06, 'tr_loss': 0.657482223212719, 'eval_val_loss': 1.0984156571402408, 'eval_val_acc': 0.7468827930174564}\n",
      "\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 802\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe692321989746bba338730d842d0046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=101, style=ProgressStyle(description_width='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final eval: {'val_loss': 1.096391393111484, 'val_acc': 0.7418952618453866}\n",
      "***** Running prediction *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4807dc16beed49a886257d6e0782dff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='iniâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 9 :\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 7226\n",
      "  Num Epochs = 12\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b023ea5817471a930e225dd9945ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 200, 'lr': 1.769593682237682e-05, 'tr_loss': 3.1963110768795016, 'eval_val_loss': 2.6942314594098837, 'eval_val_acc': 0.42144638403990026}\n",
      "{'step': 400, 'lr': 9.690767133662976e-07, 'tr_loss': 2.550589619874954, 'eval_val_loss': 2.459229659326006, 'eval_val_acc': 0.48753117206982544}\n",
      "{'step': 600, 'lr': 2.2739467854427512e-05, 'tr_loss': 2.290418952703476, 'eval_val_loss': 2.070156452679398, 'eval_val_acc': 0.5885286783042394}\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "list_preds_test = []\n",
    "preds_val_all = np.zeros((len(df_train), num_labels))\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=2019)\n",
    "\n",
    "for i, (train_ix, val_ix) in enumerate(kf.split(df_train)):\n",
    "    print(\"Fold %s :\\n\" % i)\n",
    "    sentences_tr = df_train.iloc[train_ix][\"question\"].values\n",
    "    labels_tr = df_labels.iloc[train_ix][\"intention\"].values\n",
    "    sentences_val = df_train.iloc[val_ix][\"question\"].values\n",
    "    labels_val = df_labels.iloc[val_ix][\"intention\"].values\n",
    "    \n",
    "    dataset_tr = load_and_cache_examples(sentences=sentences_tr,\n",
    "                                  labels=labels_tr,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  max_seq_length = 128,\n",
    "                                  label_list = [str(j) for j in range(51)])\n",
    "    \n",
    "    dataset_val = load_and_cache_examples(sentences=sentences_val,\n",
    "                              labels=labels_val,\n",
    "                              tokenizer=tokenizer,\n",
    "                              max_seq_length = 128,\n",
    "                              label_list = [str(j) for j in range(51)])\n",
    "    \n",
    "    \n",
    "    model = CamembertForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    train(model=model, train_dataset=dataset_tr, tokenizer=tokenizer, train_batch_size=32,\n",
    "      learning_rate=3e-5, num_train_epochs=12, evaluate_during_training=True, logging_steps=200,\n",
    "      max_grad_norm=1.0, save_steps=-1, num_cycles=6.0, verbose=0, eval_dataset=dataset_val) #  \n",
    "    \n",
    "    res_eval = evaluate(model=model, eval_dataset=dataset_val,\n",
    "                        tokenizer=tokenizer, eval_batch_size=8, prefix=\"\",\n",
    "                        eval_output_dir=None, verbose=1)\n",
    "    print(\"Final eval:\", res_eval)\n",
    "    \n",
    "    preds_val = predict(model=model, dataset=dataset_val, batch_size=8, verbose=0)\n",
    "    preds_val_all[val_ix, :] = preds_val\n",
    "    \n",
    "    preds_test = predict(model=model, dataset=test_dataset, batch_size=8, verbose=1)\n",
    "    list_preds_test.append(preds_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "path_save = \"results_tuto_camemBERT_v1_10_folds/\"\n",
    "import pickle\n",
    "\n",
    "with open(path_save + 'list_preds_test.pkl', 'wb') as f:\n",
    "    pickle.dump(list_preds_test, f)\n",
    "    \n",
    "with open(path_save + 'preds_val_all.pkl', 'wb') as f:\n",
    "    pickle.dump(preds_val_all, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open(path_save + 'list_preds_test.pkl', 'rb') as f:\n",
    "    list_preds_test = pickle.load(f)\n",
    "    \n",
    "with open(path_save + 'preds_val_all.pkl', 'rb') as f:\n",
    "    preds_val_all = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7588440458395616"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# local CV score\n",
    "accuracy_score(df_labels[\"intention\"].values, np.argmax(preds_val_all, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg pred on test\n",
    "preds_test_avg = np.zeros_like(list_preds_test[0])\n",
    "for i in range(len(list_preds_test)):\n",
    "    preds_test_avg += list_preds_test[i] / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_class_avg = np.argmax(preds_test_avg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"ID\": df_test[\"ID\"].values,  \"intention\": preds_test_class_avg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8028</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8029</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8030</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8031</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8032</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  intention\n",
       "0  8028  32       \n",
       "1  8029  32       \n",
       "2  8030  32       \n",
       "3  8031  31       \n",
       "4  8032  44       "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub/sub2_10_folds_avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
