{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_glue import set_seed, load_and_cache_examples, train, evaluate \n",
    "\n",
    "from transformers import (CamembertConfig,\n",
    "                          CamembertForSequenceClassification,\n",
    "                          CamembertTokenizer,\n",
    "                         DistilBertTokenizer)\n",
    "from torch import device\n",
    "\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from transformers import glue_compute_metrics as compute_metrics\n",
    "from transformers import glue_output_modes as output_modes\n",
    "from transformers import glue_processors as processors\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "\n",
    "from namespace import Namespace, as_namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/\"\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'camembert': (CamembertConfig, CamembertForSequenceClassification, CamembertTokenizer),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Namespace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-da3cc7dd0a47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m args = Namespace({\"adam_epsilon\": 1e-08,\n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0;34m\"cache_dir\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0;34m\"config_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0;34m\"data_dir\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0;34m\"device\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Namespace' is not defined"
     ]
    }
   ],
   "source": [
    "args = Namespace({\"adam_epsilon\": 1e-08,\n",
    "                 \"cache_dir\": '',\n",
    "                 \"config_name\": '',\n",
    "                 \"data_dir\": path_data,\n",
    "                 \"device\": device(\"cpu\"),\n",
    "                  \"do_eval\": False,\n",
    "                  \"do_lower_case\": True,\n",
    "                  \"do_train\": True,\n",
    "                  \"eval_all_checkpoints\": False,\n",
    "                  \"evaluate_during_training\": False,\n",
    "                  \"fp16\": False,\n",
    "                  \"fp16_opt_level\": 'O1',\n",
    "                  \"gradient_accumulation_steps\": 1,\n",
    "                  \"learning_rate\": 2e-05,\n",
    "                  \"local_rank\": -1,\n",
    "                  \"logging_steps\": 50,\n",
    "                  \"max_grad_norm\": 1.0,\n",
    "                  \"max_seq_length\": 128,\n",
    "                  \"max_steps\": -1,\n",
    "                  \"model_name_or_path\": \"camembert-base\",#'bert-base-cased',\n",
    "                  \"model_type\": 'camembert',\n",
    "                  \"n_gpu\": 0,\n",
    "                  \"no_cuda\": True,\n",
    "                  \"num_train_epochs\": 1, #must be int in fact !\n",
    "                  \"output_dir\":'/tmp/result',\n",
    "                  \"output_mode\":'classification',\n",
    "                  \"overwrite_cache\":True,\n",
    "                  \"overwrite_output_dir\":True,\n",
    "                  \"per_gpu_eval_batch_size\":8,\n",
    "                  \"per_gpu_train_batch_size\":32,\n",
    "                  \"save_steps\":50,\n",
    "                  \"seed\":42,\n",
    "                  \"server_ip\":'',\n",
    "                  \"server_port\":'',\n",
    "                  \"task_name\":'anna',\n",
    "                  \"tokenizer_name\":'',\n",
    "                  \"tpu\": False,\n",
    "                  \"tpu_ip_address\": '',\n",
    "                  \"tpu_name\": '',\n",
    "                  \"warmup_steps\": 0,\n",
    "                  \"weight_decay\": 0.0,\n",
    "                  \"xrt_tpu_config\": ''}\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'knowledge_20191112.tsv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"knowledge_20191112.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "set_seed(args)\n",
    "\n",
    "# Prepare GLUE task\n",
    "args.task_name = args.task_name.lower()\n",
    "if args.task_name not in processors:\n",
    "    raise ValueError(\"Task not found: %s\" % (args.task_name))\n",
    "processor = processors[args.task_name]()\n",
    "args.output_mode = output_modes[args.task_name]\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_class.from_pretrained(args.config_name if args.config_name else args.model_name_or_path,\n",
    "                                      num_labels=num_labels,\n",
    "                                      finetuning_task=args.task_name,\n",
    "                                      cache_dir=args.cache_dir if args.cache_dir else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
    "                                            do_lower_case=args.do_lower_case,\n",
    "                                            cache_dir=args.cache_dir if args.cache_dir else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_class.from_pretrained(args.model_name_or_path,\n",
    "                                    from_tf=bool('.ckpt' in args.model_name_or_path),\n",
    "                                    config=config,\n",
    "                                    cache_dir=args.cache_dir if args.cache_dir else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anna\n",
      "<class 'transformers.data.processors.glue.AnnaProcessor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_and_cache_examples(args=args,\n",
    "                                        task=\"anna\",\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        evaluate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7362"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    5, 28306,    21,  ...,     1,     1,     1],\n",
       "         [    5,   114,   484,  ...,     1,     1,     1],\n",
       "         [    5,  7363,    56,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    5,  1470,   279,  ...,     1,     1,     1],\n",
       "         [    5,  2302,    30,  ...,     1,     1,     1],\n",
       "         [    5, 30012,    35,  ...,     1,     1,     1]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " tensor([945, 141, 330,  ..., 406, 201, 747]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Iteration:   0%|          | 0/231 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   5,  841, 8241,  ...,    1,    1,    1],\n",
      "        [   5,  100, 1282,  ...,    1,    1,    1],\n",
      "        [   5, 2302,   30,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   5, 4171,    7,  ...,    1,    1,    1],\n",
      "        [   5,  841,   85,  ...,    1,    1,    1],\n",
      "        [   5, 1470,  279,  ...,    1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([596, 123, 574, 416, 770, 146, 599, 870, 732, 604,  81, 741, 737, 600,\n",
      "        900,  91, 214, 604, 221, 228,  87, 510, 342, 350, 786, 516, 214, 597,\n",
      "        443, 562, 724, 406]), 'token_type_ids': None}\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32])\n",
      "tensor(900)\n",
      "tensor(81)\n",
      "tensor([ 81,  87,  91, 123, 146, 214, 221, 228, 342, 350, 406, 416, 443, 510,\n",
      "        516, 562, 574, 596, 597, 599, 600, 604, 724, 732, 737, 741, 770, 786,\n",
      "        870, 900])\n",
      "1081\n",
      "tensor([[-0.0521,  0.0135, -0.0086,  ...,  0.0008, -0.0298,  0.0229],\n",
      "        [-0.0552,  0.0282,  0.0330,  ..., -0.0332,  0.0402,  0.0978],\n",
      "        [ 0.0253, -0.0428,  0.0447,  ..., -0.0151, -0.0599, -0.0107],\n",
      "        ...,\n",
      "        [-0.0486, -0.0537, -0.0036,  ..., -0.0401, -0.0478, -0.0109],\n",
      "        [-0.0812, -0.0199,  0.0131,  ..., -0.0191,  0.0101,  0.0172],\n",
      "        [-0.0864,  0.0098, -0.0364,  ...,  0.0074,  0.0751,  0.0102]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([596, 123, 574, 416, 770, 146, 599, 870, 732, 604,  81, 741, 737, 600,\n",
      "        900,  91, 214, 604, 221, 228,  87, 510, 342, 350, 786, 516, 214, 597,\n",
      "        443, 562, 724, 406])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration:   0%|          | 1/231 [00:41<2:39:12, 41.53s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    5,   175,    26,  ...,     1,     1,     1],\n",
      "        [    5,  7363,    56,  ...,     1,     1,     1],\n",
      "        [    5, 14050,    20,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    5,  3053,    30,  ...,     1,     1,     1],\n",
      "        [    5,   841,    48,  ...,     1,     1,     1],\n",
      "        [    5, 15294,  4171,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 189,  771,  736,  421,  732,  712,  201,   76,  181,  726,  762,  333,\n",
      "         345,  128,  745,  907,  222,  923,  318,  421,  521,    0,  405,  234,\n",
      "        1042,  704,  184,  715,  469,  565,  779,  247]), 'token_type_ids': None}\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32])\n",
      "tensor(1042)\n",
      "tensor(0)\n",
      "tensor([   0,   76,  128,  181,  184,  189,  201,  222,  234,  247,  318,  333,\n",
      "         345,  405,  421,  469,  521,  565,  704,  712,  715,  726,  732,  736,\n",
      "         745,  762,  771,  779,  907,  923, 1042])\n",
      "1081\n",
      "tensor([[-0.0632, -0.0443,  0.0079,  ..., -0.0160, -0.0494, -0.0223],\n",
      "        [ 0.0126, -0.1131,  0.0519,  ...,  0.0268, -0.0615,  0.0289],\n",
      "        [-0.0429, -0.0282,  0.0881,  ..., -0.0206, -0.0758, -0.0199],\n",
      "        ...,\n",
      "        [ 0.0034, -0.0251, -0.0429,  ..., -0.0115, -0.0626,  0.0601],\n",
      "        [-0.0373, -0.0746, -0.0026,  ...,  0.0517,  0.0143,  0.0195],\n",
      "        [-0.0334, -0.0541,  0.0233,  ..., -0.0754, -0.0428,  0.0356]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([ 189,  771,  736,  421,  732,  712,  201,   76,  181,  726,  762,  333,\n",
      "         345,  128,  745,  907,  222,  923,  318,  421,  521,    0,  405,  234,\n",
      "        1042,  704,  184,  715,  469,  565,  779,  247])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4e138b1ecbd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m       \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       tokenizer=tokenizer)\n\u001b[0m",
      "\u001b[0;32m~/Drive-Zelros/Anna-v3/transformers/examples2/anna/run_glue.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_dataset, model, tokenizer)\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args=args,\n",
    "      train_dataset=train_dataset,\n",
    "      model=model,\n",
    "      tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
