{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "\n",
    "\n",
    "import torch\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler # pour centrer et normer (variance 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/Users/yohannlefaou/Documents/data/posos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path_data +\"input_train.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(path_data + \"output_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bonjour,  je m suis trompé de forum pour ma question alors je la repose ici. je pris pour la première fois hier du paroxétine et ce matin c'est une catastrophe. picotement dasn tous le corps annonciateur de sueur froide très très massive et de vomissement. j'en suis à deux crises depuis 5 heure du mat. la cela semble passer mes mes mains reste moites et chaude estce normal pour la première fois merci a tous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>est ce que le motilium me soulagera contre les nausées?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>mon médecin m'a prescrit adenyl. au 2ème cachet des maux de tête terribles et au 3ème palpitations, sueurs froides, chaleur intense dans la tête, tremblements, fourmillements dans la lèvre supérieure, difficultés à respirer.. dès l'arrêt du médicament tous les symptômes ont disparu. cela est-il déjà arrivé à quelqu'un??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Est-ce qu'il existe une forme adaptée aux enfant de 5ans du Micropakine ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>mon  medecin  me soigne  pour  une  rhino  pharingite  et  m'a  prescrit du amoxicilline comme  anti  biotique. Est-ce vraiment pour cette indication?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  \\\n",
       "0  0    \n",
       "1  1    \n",
       "2  2    \n",
       "3  3    \n",
       "4  4    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                     question  \n",
       "0  bonjour,  je m suis trompé de forum pour ma question alors je la repose ici. je pris pour la première fois hier du paroxétine et ce matin c'est une catastrophe. picotement dasn tous le corps annonciateur de sueur froide très très massive et de vomissement. j'en suis à deux crises depuis 5 heure du mat. la cela semble passer mes mes mains reste moites et chaude estce normal pour la première fois merci a tous  \n",
       "1  est ce que le motilium me soulagera contre les nausées?                                                                                                                                                                                                                                                                                                                                                                     \n",
       "2  mon médecin m'a prescrit adenyl. au 2ème cachet des maux de tête terribles et au 3ème palpitations, sueurs froides, chaleur intense dans la tête, tremblements, fourmillements dans la lèvre supérieure, difficultés à respirer.. dès l'arrêt du médicament tous les symptômes ont disparu. cela est-il déjà arrivé à quelqu'un??                                                                                           \n",
       "3  Est-ce qu'il existe une forme adaptée aux enfant de 5ans du Micropakine ?                                                                                                                                                                                                                                                                                                                                                   \n",
       "4  mon  medecin  me soigne  pour  une  rhino  pharingite  et  m'a  prescrit du amoxicilline comme  anti  biotique. Est-ce vraiment pour cette indication?                                                                                                                                                                                                                                                                      "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  intention\n",
       "0  0   28       \n",
       "1  1   31       \n",
       "2  2   28       \n",
       "3  3   44       \n",
       "4  4   31       "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/yohannlefaou/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file http://dl.fbaipublicfiles.com/fairseq/models/camembert.v0.tar.gz from cache at /Users/yohannlefaou/.cache/torch/pytorch_fairseq/df8ea5d155cb66cfb63da3aea2b4e72963253193e2355dc97c94e3442753b1ee.d1e3eb8a6a216f388fe37b689e1278c67aa17f914c446561739f1b0aa88addf2\n",
      "| dictionary: 32004 types\n"
     ]
    }
   ],
   "source": [
    "camembert = torch.hub.load('pytorch/fairseq', 'camembert.v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonjour,  je m suis trompé de forum pour ma question alors je la repose ici. je pris pour la première fois hier du paroxétine et ce matin c'est une catastrophe. picotement dasn tous le corps annonciateur de sueur froide très très massive et de vomissement. j'en suis à deux crises depuis 5 heure du mat. la cela semble passer mes mes mains reste moites et chaude estce normal pour la première fois merci a tous\n",
      "99\n",
      "tensor([    5,  5061,     7,    50,   115,   146, 12125,     8,  1026,    24,\n",
      "          155,   397,   183,    50,    13,  4537,   323,     9,    50,   523,\n",
      "           24,    13,   272,   151,  2067,    25,    37,  5321,   141,  4030,\n",
      "           14,    44,   823,    60,    11,    41,    28,  7978,     9,  5461,\n",
      "         4613,   131,    18,   636,   255,   117,    16,   486,    21, 13758,\n",
      "          244,  1569,     8, 18416,  4185,    95,    95,  9750,    14,     8,\n",
      "        17381,  5872,     9,    76,    11,    90,   146,    15,   116, 10788,\n",
      "          176,   205,  1507,    25,  6032,     9,    13,   207,   630,   444,\n",
      "          249,   249,  1227,   353,   202,  1839,    14,  2702,    30,   291,\n",
      "         2142,    24,    13,   272,   151,   895,    33,   117,     6])\n",
      "tensor([[[-0.0164,  0.1255,  0.0708,  ..., -0.0052, -0.0440,  0.1089],\n",
      "         [-0.0398, -0.1051,  0.0364,  ...,  0.1135, -0.0541,  0.0867],\n",
      "         [-0.0297,  0.1889,  0.0516,  ...,  0.0235, -0.0065,  0.0705],\n",
      "         ...,\n",
      "         [ 0.0407,  0.2339, -0.1532,  ...,  0.0074,  0.0323,  0.0569],\n",
      "         [ 0.1275,  0.0681, -0.3239,  ...,  0.0440, -0.1040, -0.0351],\n",
      "         [-0.1937,  0.2517, -0.0232,  ..., -0.1785, -0.1437,  0.1142]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "line = train[\"question\"][0]\n",
    "print(line)\n",
    "tokens = camembert.encode(line)\n",
    "print(len(tokens))\n",
    "print(tokens)\n",
    "last_layer_features = camembert.extract_features(tokens)\n",
    "print(last_layer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 99, 768])\n"
     ]
    }
   ],
   "source": [
    "# rmq : on a un embedding de taille 768 pour chaque token\n",
    "print(last_layer_features.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b743426298ec4cb980c1a9696a8632f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8028), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# on  fait la moyenne des embeedings de tous les tokens\n",
    "max_tokens = 512 # maximum number of tokens in order to compute embeddings\n",
    "sentence_tokens = []\n",
    "sentence_embeddings = []\n",
    "for i in tqdm(range(len(train))):\n",
    "    line = train[\"question\"][i]\n",
    "    tokens = camembert.encode(line)\n",
    "    sentence_tokens.append(tokens)\n",
    "    last_layer_features = camembert.extract_features(tokens[:max_tokens])\n",
    "    sentence_embeddings.append(torch.mean(last_layer_features, dim=1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQhklEQVR4nO3db6yedX3H8fdnVHHTTYocSNfiirHZxCUCaaCOPXDgSgFjeQAJxIyGNekTluFiorA9aPxDAskiSDKJRDrROJChjgaNrCmQZQ8EymAIVNYjMOhgtK4F54xG9LsH9/fgTT2n52/PaU/fr+TOff2+1++679/vvk7y6fXnvpuqQpKk31joAUiSDg8GgiQJMBAkSc1AkCQBBoIkqS1Z6AEczAknnFArV65c6GFI0hHlkUce+WFVjUx3u8M6EFauXMmOHTsWehiSdERJ8p8z2c5TRpIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRIwxUBI8lyS7yV5LMmOrh2fZFuSXf28tOtJclOS0SSPJzlj6HU2dP9dSTYcmilJkmZiOkcIf1JVp1XV6m5fDWyvqlXA9m4DnA+s6scm4GYYBAiwGTgLOBPYPBYikqSFN5tvKq8HPtDLtwEPAJ/o+pdr8D/vfDfJcUmWdd9tVbUPIMk2YB1w+yzGcFArr/7WuPXnrrvwUL2lJB2xpnqEUMA/J3kkyaaunVRVLwH084ldXw68MLTt7q5NVJckHQameoRwdlW9mOREYFuS7x+kb8ap1UHqb9x4EDibAN75zndOcXiSpNma0hFCVb3Yz3uAbzK4BvBynwqin/d0993AyUObrwBePEj9wPe6papWV9XqkZFp/1ifJGmGJg2EJG9N8ttjy8Ba4AlgKzB2p9AG4O5e3gpc3ncbrQFe7VNK9wJrkyzti8lruyZJOgxM5ZTRScA3k4z1/4eq+k6Sh4E7k2wEngcu6f7fBi4ARoGfAFcAVNW+JJ8GHu5+nxq7wCxJWniTBkJVPQO8b5z6/wDnjlMv4MoJXmsLsGX6w5QkHWp+U1mSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCS1KQdCkmOSPJrknm6fkuTBJLuSfC3Jm7t+bLdHe/3Kode4putPJzlvricjSZq56RwhXAXsHGpfD9xQVauA/cDGrm8E9lfVu4Ebuh9JTgUuBd4LrAM+n+SY2Q1fkjRXphQISVYAFwJf7HaAc4C7usttwEW9vL7b9Ppzu/964I6q+llVPQuMAmfOxSQkSbM31SOEG4GPA7/s9juAV6rqtW7vBpb38nLgBYBe/2r3f70+zjaSpAU2aSAk+RCwp6oeGS6P07UmWXewbYbfb1OSHUl27N27d7LhSZLmyFSOEM4GPpzkOeAOBqeKbgSOS7Kk+6wAXuzl3cDJAL3+7cC+4fo427yuqm6pqtVVtXpkZGTaE5IkzcykgVBV11TViqpayeCi8H1V9RHgfuDi7rYBuLuXt3abXn9fVVXXL+27kE4BVgEPzdlMJEmzsmTyLhP6BHBHks8AjwK3dv1W4CtJRhkcGVwKUFVPJrkTeAp4Dbiyqn4xi/eXJM2haQVCVT0APNDLzzDOXUJV9VPgkgm2vxa4drqDlCQden5TWZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIETCEQkrwlyUNJ/j3Jk0k+2fVTkjyYZFeSryV5c9eP7fZor1859FrXdP3pJOcdqklJkqZvKkcIPwPOqar3AacB65KsAa4HbqiqVcB+YGP33wjsr6p3Azd0P5KcClwKvBdYB3w+yTFzORlJ0sxNGgg18ONuvqkfBZwD3NX124CLenl9t+n15yZJ1++oqp9V1bPAKHDmnMxCkjRrU7qGkOSYJI8Be4BtwA+AV6rqte6yG1jey8uBFwB6/avAO4br42wz/F6bkuxIsmPv3r3Tn5EkaUamFAhV9YuqOg1YweBf9e8Zr1s/Z4J1E9UPfK9bqmp1Va0eGRmZyvAkSXNgWncZVdUrwAPAGuC4JEt61QrgxV7eDZwM0OvfDuwbro+zjSRpgU3lLqORJMf18m8CHwR2AvcDF3e3DcDdvby12/T6+6qqun5p34V0CrAKeGiuJiJJmp0lk3dhGXBb3xH0G8CdVXVPkqeAO5J8BngUuLX73wp8JckogyODSwGq6skkdwJPAa8BV1bVL+Z2OpKkmZo0EKrqceD0cerPMM5dQlX1U+CSCV7rWuDa6Q9TknSo+U1lSRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1CYNhCQnJ7k/yc4kTya5quvHJ9mWZFc/L+16ktyUZDTJ40nOGHqtDd1/V5INh25akqTpmsoRwmvAx6rqPcAa4MokpwJXA9urahWwvdsA5wOr+rEJuBkGAQJsBs4CzgQ2j4WIJGnhTRoIVfVSVf1bL/8vsBNYDqwHbututwEX9fJ64Ms18F3guCTLgPOAbVW1r6r2A9uAdXM6G0nSjE3rGkKSlcDpwIPASVX1EgxCAzixuy0HXhjabHfXJqof+B6bkuxIsmPv3r3TGZ4kaRamHAhJ3gZ8HfhoVf3oYF3HqdVB6m8sVN1SVauravXIyMhUhydJmqUpBUKSNzEIg69W1Te6/HKfCqKf93R9N3Dy0OYrgBcPUpckHQamcpdRgFuBnVX12aFVW4GxO4U2AHcP1S/vu43WAK/2KaV7gbVJlvbF5LVdkyQdBpZMoc/ZwJ8B30vyWNf+GrgOuDPJRuB54JJe923gAmAU+AlwBUBV7UvyaeDh7vepqto3J7OQJM3apIFQVf/K+Of/Ac4dp38BV07wWluALdMZoCRpfvhNZUkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCS1qfza6aKz8upvjVt/7roL53kkknT48AhBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkoApBEKSLUn2JHliqHZ8km1JdvXz0q4nyU1JRpM8nuSMoW02dP9dSTYcmulIkmZqKkcIXwLWHVC7GtheVauA7d0GOB9Y1Y9NwM0wCBBgM3AWcCaweSxEJEmHh0kDoar+Bdh3QHk9cFsv3wZcNFT/cg18FzguyTLgPGBbVe2rqv3ANn49ZCRJC2im1xBOqqqXAPr5xK4vB14Y6re7axPVf02STUl2JNmxd+/eGQ5PkjRdc31ROePU6iD1Xy9W3VJVq6tq9cjIyJwOTpI0sZkGwst9Koh+3tP13cDJQ/1WAC8epC5JOkzMNBC2AmN3Cm0A7h6qX953G60BXu1TSvcCa5Ms7YvJa7smSTpMLJmsQ5LbgQ8AJyTZzeBuoeuAO5NsBJ4HLunu3wYuAEaBnwBXAFTVviSfBh7ufp+qqgMvVEuSFtCkgVBVl02w6txx+hZw5QSvswXYMq3RSZLmjd9UliQBBoIkqRkIkiTAQJAktUkvKh9NVl79rXHrz1134TyPRJLmn0cIkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTA/zFtSvyf1CQdDTxCkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKk5m2ns+DtqJIWE48QJEmAgSBJavN+yijJOuBzwDHAF6vquvkew6HmqSRJR6J5DYQkxwB/B/wpsBt4OMnWqnpqPsexUAwKSYez+T5COBMYrapnAJLcAawHjopAmMhEQXE4MrykxWu+A2E58MJQezdw1nCHJJuATd38cZKnZ/heJwA/nOG2R7pDNvdcfyhedU65349Ozv2Nfm8mLzTfgZBxavWGRtUtwC2zfqNkR1Wtnu3rHImcu3M/2jj3uZn7fN9ltBs4eai9AnhxnscgSRrHfAfCw8CqJKckeTNwKbB1nscgSRrHvJ4yqqrXkvwFcC+D2063VNWTh+jtZn3a6Qjm3I9Ozv3oNGdzT1VN3kuStOj5TWVJEmAgSJLaoguEJOuSPJ1kNMnVCz2euZbk5CT3J9mZ5MkkV3X9+CTbkuzq56VdT5Kb+vN4PMkZCzuD2UtyTJJHk9zT7VOSPNhz/1rfsECSY7s92utXLuS4ZyvJcUnuSvL93v/vP1r2e5K/6r/3J5LcnuQti3m/J9mSZE+SJ4Zq097XSTZ0/11JNkz2vosqEIZ+GuN84FTgsiSnLuyo5txrwMeq6j3AGuDKnuPVwPaqWgVs7zYMPotV/dgE3Dz/Q55zVwE7h9rXAzf03PcDG7u+EdhfVe8Gbuh+R7LPAd+pqj8A3sfgM1j0+z3JcuAvgdVV9YcMbki5lMW9378ErDugNq19neR4YDODL/+eCWweC5EJVdWieQDvB+4dal8DXLPQ4zrEc76bwW9DPQ0s69oy4Ole/gJw2VD/1/sdiQ8G313ZDpwD3MPgy44/BJYc+DfA4G629/fyku6XhZ7DDOf9O8CzB47/aNjv/OoXDo7v/XgPcN5i3+/ASuCJme5r4DLgC0P1N/Qb77GojhAY/6cxli/QWA65PhQ+HXgQOKmqXgLo5xO722L7TG4EPg78stvvAF6pqte6PTy/1+fe61/t/keidwF7gb/v02VfTPJWjoL9XlX/Bfwt8DzwEoP9+AhHx34fNt19Pe2/gcUWCJP+NMZikeRtwNeBj1bVjw7WdZzaEfmZJPkQsKeqHhkuj9O1prDuSLMEOAO4uapOB/6PX50yGM+imXuf5lgPnAL8LvBWBqdJDrQY9/tUTDTfaX8Oiy0QjoqfxkjyJgZh8NWq+kaXX06yrNcvA/Z0fTF9JmcDH07yHHAHg9NGNwLHJRn7kuXw/F6fe69/O7BvPgc8h3YDu6vqwW7fxSAgjob9/kHg2araW1U/B74B/BFHx34fNt19Pe2/gcUWCIv+pzGSBLgV2FlVnx1atRUYu4tgA4NrC2P1y/tOhDXAq2OHnUeaqrqmqlZU1UoG+/a+qvoIcD9wcXc7cO5jn8nF3f+I/JdiVf038EKS3+/SuQx+Nn7R73cGp4rWJPmt/vsfm/ui3+8HmO6+vhdYm2RpH2Wt7drEFvrCySG4EHMB8B/AD4C/WejxHIL5/TGDw77Hgcf6cQGDc6TbgV39fHz3D4M7r34AfI/BnRoLPo85+Bw+ANzTy+8CHgJGgX8Eju36W7o92uvftdDjnuWcTwN29L7/J2Dp0bLfgU8C3weeAL4CHLuY9ztwO4PrJT9n8C/9jTPZ18Cf9+cwClwx2fv60xWSJGDxnTKSJM2QgSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSe3/AUiFHxG+ufiEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histo du nb de tokens par phrase (question)\n",
    "plt.hist([tokens.size()[0] for tokens in sentence_tokens], bins=50)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.DataFrame(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train2.to_csv(path_data + \"sentence_embeddings_mean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.read_csv(path_data + \"sentence_embeddings_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "train2 = sc.fit_transform(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train2, labels[\"intention\"].values, test_size=0.2,\n",
    "                                                      random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "\n",
    "Il semble y avoir beaucoup d'interractions dans les data et donc augmenter la profondeur des arbres augmentent les perf. Intéressant de voir si un réseau de neurones ferait des meilleures perf ici. ça serait un insight intéressant de constater cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 20, n_estimators=100) # max_features=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 197 ms, total: 22.2 s\n",
      "Wall time: 22.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36737235367372356"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, rf.predict(X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yohannlefaou/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "# one hot encode the target\n",
    "ohe = OneHotEncoder()\n",
    "one_hot_encode_labels = ohe.fit_transform(labels[\"intention\"].values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train2, one_hot_encode_labels, test_size=0.2,\n",
    "                                                      random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dropout(0.2, input_shape=(768,)))\n",
    "nn.add(Dense(1024, input_dim= 768, activation=\"relu\")) # input_dim= 768\n",
    "#nn.add(Dropout(0.3))\n",
    "nn.add(Dense(256, activation=\"relu\"))\n",
    "#nn.add(Dropout(0.3))\n",
    "nn.add(Dense(51, activation=\"softmax\")) #a completer\n",
    "\n",
    "nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/10\n",
      "6422/6422 [==============================] - 18s 3ms/step - loss: 2.4578 - accuracy: 0.3748 - val_loss: 2.0187 - val_accuracy: 0.4826\n",
      "Epoch 2/10\n",
      "6422/6422 [==============================] - 19s 3ms/step - loss: 1.7762 - accuracy: 0.5079 - val_loss: 1.7991 - val_accuracy: 0.5230\n",
      "Epoch 3/10\n",
      "6422/6422 [==============================] - 17s 3ms/step - loss: 1.5171 - accuracy: 0.5696 - val_loss: 1.5448 - val_accuracy: 0.5654\n",
      "Epoch 4/10\n",
      "6422/6422 [==============================] - 17s 3ms/step - loss: 1.3172 - accuracy: 0.6190 - val_loss: 1.5016 - val_accuracy: 0.5996\n",
      "Epoch 5/10\n",
      "6422/6422 [==============================] - 16s 3ms/step - loss: 1.1895 - accuracy: 0.6495 - val_loss: 1.5090 - val_accuracy: 0.6009\n",
      "Epoch 6/10\n",
      "6422/6422 [==============================] - 17s 3ms/step - loss: 1.0628 - accuracy: 0.6937 - val_loss: 1.4059 - val_accuracy: 0.6046\n",
      "Epoch 7/10\n",
      "6422/6422 [==============================] - 18s 3ms/step - loss: 0.9619 - accuracy: 0.7119 - val_loss: 1.3770 - val_accuracy: 0.6214\n",
      "Epoch 8/10\n",
      "6422/6422 [==============================] - 18s 3ms/step - loss: 0.8761 - accuracy: 0.7312 - val_loss: 1.4472 - val_accuracy: 0.6270\n",
      "Epoch 9/10\n",
      "6422/6422 [==============================] - 16s 2ms/step - loss: 0.7627 - accuracy: 0.7667 - val_loss: 1.4486 - val_accuracy: 0.6320\n",
      "Epoch 10/10\n",
      "6422/6422 [==============================] - 16s 2ms/step - loss: 0.6888 - accuracy: 0.7879 - val_loss: 1.4169 - val_accuracy: 0.6413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a8a1a4e90>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5) # \n",
    "\n",
    "nn.fit(np.array(X_train), y_train, epochs=10, batch_size=10,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) # , callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/4\n",
      "6422/6422 [==============================] - 19s 3ms/step - loss: 0.6390 - accuracy: 0.7965 - val_loss: 1.5028 - val_accuracy: 0.6445\n",
      "Epoch 2/4\n",
      "6422/6422 [==============================] - 18s 3ms/step - loss: 0.5806 - accuracy: 0.8153 - val_loss: 1.4934 - val_accuracy: 0.6357\n",
      "Epoch 3/4\n",
      "6422/6422 [==============================] - 18s 3ms/step - loss: 0.5313 - accuracy: 0.8315 - val_loss: 1.5606 - val_accuracy: 0.6177\n",
      "Epoch 4/4\n",
      "6422/6422 [==============================] - 19s 3ms/step - loss: 0.4692 - accuracy: 0.8527 - val_loss: 1.5602 - val_accuracy: 0.6482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a6e39c150>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=4, batch_size=10,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) # , callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/1\n",
      "6422/6422 [==============================] - 2s 329us/step - loss: 0.3530 - accuracy: 0.8874 - val_loss: 1.4802 - val_accuracy: 0.6650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a6e39c390>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=1, batch_size=128,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) # , callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/1\n",
      "6422/6422 [==============================] - 2s 327us/step - loss: 0.2781 - accuracy: 0.9154 - val_loss: 1.4948 - val_accuracy: 0.6644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a6e39c9d0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=1, batch_size=128,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) # , callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/1\n",
      "6422/6422 [==============================] - 2s 330us/step - loss: 0.2664 - accuracy: 0.9187 - val_loss: 1.5161 - val_accuracy: 0.6631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a89f63190>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=1, batch_size=128,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) # , callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0258f0ebd6c84839a1b5c9c76bb6318d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8028), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# on  fait la moyenne des embeedings de tous les tokens\n",
    "max_tokens = 512 # maximum number of tokens in order to compute embeddings\n",
    "sentence_tokens = []\n",
    "sentence_embeddings = []\n",
    "for i in tqdm(range(len(train))):\n",
    "    line = train[\"question\"][i]\n",
    "    tokens = camembert.encode(line)\n",
    "    sentence_tokens.append(tokens)\n",
    "    last_layer_features = camembert.extract_features(tokens[:max_tokens])\n",
    "    sentence_embeddings.append(torch.max(last_layer_features, dim=1)[0].squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histo du nb de tokens par phrase (question)\n",
    "plt.hist([tokens.size()[0] for tokens in sentence_tokens], bins=50)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.DataFrame(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.to_csv(path_data + \"sentence_embeddings_max.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "train2 = sc.fit_transform(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train2, labels[\"intention\"].values, test_size=0.2,\n",
    "                                                      random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yohannlefaou/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "# one hot encode the target\n",
    "ohe = OneHotEncoder()\n",
    "one_hot_encode_labels = ohe.fit_transform(labels[\"intention\"].values.reshape(-1, 1)).toarray()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train2, one_hot_encode_labels, test_size=0.2,\n",
    "                                                      random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "#nn.add(Dropout(0.2, input_shape=(768,)))\n",
    "nn.add(Dense(1024, input_dim= 768, activation=\"relu\")) # input_dim= 768\n",
    "nn.add(Dropout(0.3))\n",
    "nn.add(Dense(256, activation=\"relu\"))\n",
    "nn.add(Dropout(0.3))\n",
    "nn.add(Dense(51, activation=\"softmax\")) #a completer\n",
    "\n",
    "nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 8s 1ms/step - loss: 2.7096 - accuracy: 0.3440 - val_loss: 2.1000 - val_accuracy: 0.4745\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 7s 1ms/step - loss: 1.7725 - accuracy: 0.5329 - val_loss: 1.9189 - val_accuracy: 0.5112\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 7s 1ms/step - loss: 1.3362 - accuracy: 0.6333 - val_loss: 1.7558 - val_accuracy: 0.5423\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 7s 1ms/step - loss: 1.0000 - accuracy: 0.7155 - val_loss: 1.7566 - val_accuracy: 0.5535\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 7s 1ms/step - loss: 0.7837 - accuracy: 0.7686 - val_loss: 1.8883 - val_accuracy: 0.5585\n",
      "Epoch 6/30\n",
      "6422/6422 [==============================] - 7s 1ms/step - loss: 0.6267 - accuracy: 0.8100 - val_loss: 1.9262 - val_accuracy: 0.5685\n",
      "Epoch 7/30\n",
      "6422/6422 [==============================] - 7s 1ms/step - loss: 0.5582 - accuracy: 0.8354 - val_loss: 1.9469 - val_accuracy: 0.5648\n",
      "Epoch 8/30\n",
      "6422/6422 [==============================] - 7s 1ms/step - loss: 0.4504 - accuracy: 0.8650 - val_loss: 2.2046 - val_accuracy: 0.5430\n",
      "Epoch 9/30\n",
      "6422/6422 [==============================] - 7s 1ms/step - loss: 0.4295 - accuracy: 0.8656 - val_loss: 2.2319 - val_accuracy: 0.5660\n",
      "Epoch 10/30\n",
      "2592/6422 [===========>..................] - ETA: 4s - loss: 0.3128 - accuracy: 0.8970"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b41641e60844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m nn.fit(np.array(X_train), y_train, epochs=30, batch_size=32,\n\u001b[0;32m----> 4\u001b[0;31m        validation_data=(np.array(X_valid), y_valid), shuffle=True) # , callbacks=[es]\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5) # \n",
    "\n",
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=32,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) # , callbacks=[es]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ne plus faire la somme des embeddings pour les différents tokens, il est nécessaire de padder avec des tokens 0 pour compléter les phrases. Si on considère 512 tokens max, alors on a un embedding de dim 728 par token, ce qui fait une dimension 512 * 768 par observation ! C'est énorme et ça pause des problèmes de mémoire (et en plus c'est lent à construire en appelant CamemBERT !) car 20Go nécessaire en tout pour stocker les embeddings ! Donc ici la stratégie est de limiter le nombre de tokens par phrase (en passant à 100 tokens max on desceng à 4Go ... ce qui semble ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d69454c7c8340c2b910f42a6b612210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8028), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# sentence embeddings with pad (je pad avec des 0 pour l'instant...)\n",
    "max_tokens = 100\n",
    "sentence_embeddings_full = []\n",
    "for i in tqdm(range(len(train))):\n",
    "    line = train[\"question\"][i]\n",
    "    tokens = camembert.encode(line)\n",
    "    tokens = tokens[:max_tokens]\n",
    "    tokens = torch.cat((tokens, torch.zeros(max_tokens - tokens.size()[0]).type(torch.LongTensor)), 0)\n",
    "    last_layer_features = camembert.extract_features(tokens)\n",
    "    sentence_embeddings_full.append(last_layer_features.view(-1).tolist())\n",
    "    \n",
    "# faire un gérateur mais ça serait trop lent..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data + 'sentence_embeddings_full.pkl', 'wb') as f:\n",
    "    pickle.dump(sentence_embeddings_full, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sentence_embeddings_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(path_data + 'parrot.pkl', 'rb') as f:\n",
    "#    mynewlist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = pd.DataFrame(sentence_embeddings_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3.to_csv(path_data + \"sentence_embeddings_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = pd.read_csv(path_data + \"sentence_embeddings_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4932467584"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data + 'sentence_embeddings_full_X_train.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train.drop(columns=\"Unnamed: 0\"), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data + 'sentence_embeddings_full_X_valid.pkl', 'wb') as f:\n",
    "    pickle.dump(X_valid.drop(columns=\"Unnamed: 0\"), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yohannlefaou/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "# one hot encode the target\n",
    "ohe = OneHotEncoder()\n",
    "one_hot_encode_labels = ohe.fit_transform(labels[\"intention\"].values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train3, one_hot_encode_labels, test_size=0.2,\n",
    "                                                      random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(256, input_dim= 76800, activation=\"relu\"))\n",
    "#nn.add(Dropout(0.3))\n",
    "nn.add(Dense(51, activation=\"softmax\"))\n",
    "\n",
    "nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 316s 49ms/step - loss: 3.1577 - accuracy: 0.2182 - val_loss: 3.2257 - val_accuracy: 0.2316\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 324s 50ms/step - loss: 2.8946 - accuracy: 0.2465 - val_loss: 3.0466 - val_accuracy: 0.2503\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 304s 47ms/step - loss: 2.6643 - accuracy: 0.2794 - val_loss: 3.1340 - val_accuracy: 0.2192\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 291s 45ms/step - loss: 2.4523 - accuracy: 0.3186 - val_loss: 3.1343 - val_accuracy: 0.2372\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 290s 45ms/step - loss: 2.2461 - accuracy: 0.3617 - val_loss: 3.1565 - val_accuracy: 0.2385\n",
      "Epoch 6/30\n",
      "1320/6422 [=====>........................] - ETA: 3:40 - loss: 1.9521 - accuracy: 0.4273"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-49eefc67bfb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m nn.fit(np.array(X_train), y_train, epochs=30, batch_size=10,\n\u001b[0;32m----> 4\u001b[0;31m        validation_data=(np.array(X_valid), y_valid), shuffle=True) # , callbacks=[es]\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5) # \n",
    "\n",
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=10,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) # , callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6422, 76800)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
