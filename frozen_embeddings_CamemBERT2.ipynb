{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/Users/yohannlefaou/Documents/data/posos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path_data +\"input_train.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(path_data + \"output_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bonjour,  je m suis trompé de forum pour ma question alors je la repose ici. je pris pour la première fois hier du paroxétine et ce matin c'est une catastrophe. picotement dasn tous le corps annonciateur de sueur froide très très massive et de vomissement. j'en suis à deux crises depuis 5 heure du mat. la cela semble passer mes mes mains reste moites et chaude estce normal pour la première fois merci a tous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>est ce que le motilium me soulagera contre les nausées?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>mon médecin m'a prescrit adenyl. au 2ème cachet des maux de tête terribles et au 3ème palpitations, sueurs froides, chaleur intense dans la tête, tremblements, fourmillements dans la lèvre supérieure, difficultés à respirer.. dès l'arrêt du médicament tous les symptômes ont disparu. cela est-il déjà arrivé à quelqu'un??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Est-ce qu'il existe une forme adaptée aux enfant de 5ans du Micropakine ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>mon  medecin  me soigne  pour  une  rhino  pharingite  et  m'a  prescrit du amoxicilline comme  anti  biotique. Est-ce vraiment pour cette indication?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  \\\n",
       "0  0    \n",
       "1  1    \n",
       "2  2    \n",
       "3  3    \n",
       "4  4    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                     question  \n",
       "0  bonjour,  je m suis trompé de forum pour ma question alors je la repose ici. je pris pour la première fois hier du paroxétine et ce matin c'est une catastrophe. picotement dasn tous le corps annonciateur de sueur froide très très massive et de vomissement. j'en suis à deux crises depuis 5 heure du mat. la cela semble passer mes mes mains reste moites et chaude estce normal pour la première fois merci a tous  \n",
       "1  est ce que le motilium me soulagera contre les nausées?                                                                                                                                                                                                                                                                                                                                                                     \n",
       "2  mon médecin m'a prescrit adenyl. au 2ème cachet des maux de tête terribles et au 3ème palpitations, sueurs froides, chaleur intense dans la tête, tremblements, fourmillements dans la lèvre supérieure, difficultés à respirer.. dès l'arrêt du médicament tous les symptômes ont disparu. cela est-il déjà arrivé à quelqu'un??                                                                                           \n",
       "3  Est-ce qu'il existe une forme adaptée aux enfant de 5ans du Micropakine ?                                                                                                                                                                                                                                                                                                                                                   \n",
       "4  mon  medecin  me soigne  pour  une  rhino  pharingite  et  m'a  prescrit du amoxicilline comme  anti  biotique. Est-ce vraiment pour cette indication?                                                                                                                                                                                                                                                                      "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  intention\n",
       "0  0   28       \n",
       "1  1   31       \n",
       "2  2   28       \n",
       "3  3   44       \n",
       "4  4   31       "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "\n",
    "# load model\n",
    "model = CamembertModel.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁bonjour', ',', '▁je', '▁m', '▁suis', '▁trompé', '▁de', '▁forum', '▁pour', '▁ma', '▁question', '▁alors', '▁je', '▁la', '▁repose', '▁ici', '.', '▁je', '▁pris', '▁pour', '▁la', '▁première', '▁fois', '▁hier', '▁du', '▁par', 'ox', 'é', 'tine', '▁et', '▁ce', '▁matin', '▁c', \"'\", 'est', '▁une', '▁catastrophe', '.', '▁pic', 'ote', 'ment', '▁d', 'as', 'n', '▁tous', '▁le', '▁corps', '▁', 'annon', 'ci', 'ateur', '▁de', '▁sueur', '▁froide', '▁très', '▁très', '▁massive', '▁et', '▁de', '▁vomi', 'ssement', '.', '▁j', \"'\", 'en', '▁suis', '▁à', '▁deux', '▁crises', '▁depuis', '▁5', '▁heure', '▁du', '▁mat', '.', '▁la', '▁cela', '▁semble', '▁passer', '▁mes', '▁mes', '▁mains', '▁reste', '▁moi', 'tes', '▁et', '▁chaude', '▁est', 'ce', '▁normal', '▁pour', '▁la', '▁première', '▁fois', '▁merci', '▁a', '▁tous', '</s>']\n",
      "tensor([[    5,  5061,     7,    50,   115,   146, 12125,     8,  1026,    24,\n",
      "           155,   397,   183,    50,    13,  4537,   323,     9,    50,   523,\n",
      "            24,    13,   272,   151,  2067,    25,    37,  5321,   141,  4030,\n",
      "            14,    44,   823,    60,    11,    41,    28,  7978,     9,  5461,\n",
      "          4613,   131,    18,   636,   255,   117,    16,   486,    21, 13758,\n",
      "           244,  1569,     8, 18416,  4185,    95,    95,  9750,    14,     8,\n",
      "         17381,  5872,     9,    76,    11,    90,   146,    15,   116, 10788,\n",
      "           176,   205,  1507,    25,  6032,     9,    13,   207,   630,   444,\n",
      "           249,   249,  1227,   353,   202,  1839,    14,  2702,    30,   291,\n",
      "          2142,    24,    13,   272,   151,   895,    33,   117,     6]])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "text = train[\"question\"][0]\n",
    "\n",
    "# encode() automatically adds the classification token <s>\n",
    "token_ids = tokenizer.encode(text)\n",
    "tokens = [tokenizer._convert_id_to_token(idx) for idx in token_ids]\n",
    "print(tokens)\n",
    "\n",
    "# unsqueeze token_ids because batch_size=1\n",
    "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "print(token_ids)\n",
    "\n",
    "# forward method returns a tuple (we only want the logits)\n",
    "# squeeze() because batch_size=1\n",
    "output = model(token_ids)[0].squeeze()\n",
    "# only grab output of CLS token (<s>), which is the first token\n",
    "cls_out = output[0]\n",
    "print(cls_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    5,    50,  4608,  8331,   850,   451,    17,   286,   176,    20,\n",
       "           318,     7,     8,   124,    15,   135, 26347,    10,    15,   135,\n",
       "         19365,     7,   395,   129,   956,     8,   742,  5472,    15,   742,\n",
       "          5228,    43,   118, 26347,    10,    15,  5378,     7,    27,    76,\n",
       "            11,    73,  3470,    15,   124,    38,  2156, 10831,    10, 13770,\n",
       "           280,   101,   120,    22,   732,   136,    49,    11, 12029,    34,\n",
       "            72,    38, 12699,    10, 14443,    35,     7,   792,     8,   254,\n",
       "             7,  2959,   142,    76,    11,    73,   380,    23,   281, 12960,\n",
       "            18,    10,    23,    60,  3589,    31,    33,    67,  6834,    15,\n",
       "           118, 26347,    10,    38, 12067,  2802,  5378,    53,   387, 14742,\n",
       "           118, 26484,    10, 10263,    67,  6834,    15,   135, 26347,    10,\n",
       "          3120,  2195,  5378,    53,   387, 14742,   135,  1075,   129,   956,\n",
       "          1432,    95,  2935,    65,    34,   334,    38, 27022,    10,     7,\n",
       "            21, 15240,     7,    21, 21105,     7, 11774,   312,  4242,     7,\n",
       "          2959,    53,   145,    16, 12960,    27,    76,    11,    73, 15566,\n",
       "            33,    67, 14019,    15,   118, 26347,    10,    38, 12067,  2802,\n",
       "          5378,    53,    51,   102,    33,   135,  1075,    76,    11,    90,\n",
       "           768,    72,  7158,   141,   387, 14742,   119,   135,  1075,     7,\n",
       "            14,   241,   136,  1246,    15,  1068,    15,   632,   334,     9,\n",
       "            50,    17,    11,    73, 15566,   405,    11,   265,    14,    51,\n",
       "           115,    11,    55,  2548,    18,    11,  1012,    38,  3369,   215,\n",
       "          6053,   793,  1257, 14883,   124,    37,   209,    53,   597,  4129,\n",
       "          9234,   324,    24,  4655,     7,    14,   118,    15,   135,   758,\n",
       "          1889,   290, 17047,   800,   268,   209,    32,    16,   262,     7,\n",
       "            50,   103,   146,   227,    24,   518,  1631,  6195,    34,     9,\n",
       "             9,    65,   380,   129,   956,    87,  2265,  4483,    10,  8178,\n",
       "           130,   176,    27,    50,  1460,    44, 12960,     7,    31,  4858,\n",
       "           122,  1702,  2465,    18,    11,    70,  4032,    32,    17,    11,\n",
       "           369,  3120,  1075, 10263,    14,   135,  1075,   136,   103,  8379,\n",
       "          2469,    79, 22156,    24,  6665,     8,    17,    11,  4001,    18,\n",
       "            11,    59, 17259,    53,    76,    11,    73,  1020,     8,   111,\n",
       "            85,  1074,    15,   281,     7,   380,    27,    19,   151,  7450,\n",
       "            14,    76,    11,    73,  1020,     8,   999,    18,    11,  1012,\n",
       "             9,     9,    67,    46,    11,    41,    44,    27,   136,    39,\n",
       "         17272,   106,    67,  3463,    39,    27,    60, 10970,  6053,   793,\n",
       "            30,    23,    87,  2996,   130,  3874,    38,   169,   313,    15,\n",
       "            13,   282,    18,    11,  8888,   850,   451,    53,   106,    67,\n",
       "            16, 17259,    18,    11,  8888,   850,   451,     8,   119,  1194,\n",
       "          1075, 26979,    51,    15,    87, 16810,  4139,   130,   129,  5116,\n",
       "           102, 21801,    38, 13538,    19,    21, 27022,    10,   120,    76,\n",
       "            11,    73,   523,  8331,   850,   451,    22,  9030,    15,    17,\n",
       "            11, 16309,   189,    38,    62,    49,    11,   230,    34,   143,\n",
       "         14856,    53,    14,    76,    11,   524,    20,    21, 27022,    10,\n",
       "            38,  3445,    35,    13,   656,    53, 22492,   422,    36,  5302,\n",
       "         23143,   219,   597,    48,    81,    41,    55,   387, 14742,    20,\n",
       "           250,    38,  1560,  2070,    37,    85,    28,   271,    10,   120,\n",
       "            67,    50,   146, 26338,    35,  1087,   108,  2141,    67,   161,\n",
       "          3874,   176,  6306,   239,   134,    38,  5056, 16465,    93,    86,\n",
       "            15,   787, 18704,    50,    45, 27102,    87,   650,   130,   135,\n",
       "         19365,    18,    11,  8888,   850,   451,    17,   286,   120,    76,\n",
       "            11,    73,   523, 14060, 15411,  3193,    15,    28,  2246,    31,\n",
       "           115,    11,    55,    72,    33,  1139,    38,    62,    49,    11,\n",
       "            55,    34,  1913,   103,    16, 28438,    53,    67,    22, 28045,\n",
       "         18763,    14,    87,  5171,   130,    42,   129,    21, 30871,     9,\n",
       "             9,    76,    11,  4866,    27,    50,   146,   271, 17364,  2257,\n",
       "         28051,    35,     7,   129, 12960,    26,  2037,  7583,    10,    45,\n",
       "           115,    11, 14139,    34,   237,  1074,     7,    60,    11,   230,\n",
       "            95, 12066,    78,  4032,     7,    13,  4966,    38,    62,   102,\n",
       "            33,   135,  1075,    53,    99,     9,    76,    11,    73,   792,\n",
       "             8,   111,    85,  1074,    65,    50,  1115,    27,    50,    49,\n",
       "            11,   105,  1242,  2475,     7,    15,   625,     8,    44,    87,\n",
       "           105, 21801,   130,     8, 17259,   119,  1194,  1075,    38,   662,\n",
       "           103,   146,  6215,    35,    86,   295,    27,    76,    11,    73,\n",
       "          3237,    15,  1110,    28,    21, 15721,    24,   103,    85,  4655,\n",
       "          9383,   895,    37,  3161,    24,   140,   710,   268,  3376,     9,\n",
       "             9,     6]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4676263cd58b45a699c13387b85a3e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8028), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compute embeddings for all questions\n",
    "max_tokens = 512 # maximum allowed number of tokens in one sentence in order to compute embeddings\n",
    "sentence_tokens = []\n",
    "sentence_embeddings = []\n",
    "for i in tqdm(range(len(train))):\n",
    "    text = train[\"question\"][i]\n",
    "    token_ids = tokenizer.encode(text)\n",
    "    token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "    sentence_tokens.append(token_ids)\n",
    "    output = model(token_ids[:, :max_tokens])[0].squeeze()\n",
    "    sentence_embeddings.append(output[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.DataFrame(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.103260</td>\n",
       "      <td>0.164496</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.035828</td>\n",
       "      <td>-0.014292</td>\n",
       "      <td>-0.012606</td>\n",
       "      <td>-0.057755</td>\n",
       "      <td>0.201483</td>\n",
       "      <td>0.020815</td>\n",
       "      <td>0.107380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003843</td>\n",
       "      <td>-0.086718</td>\n",
       "      <td>-0.041593</td>\n",
       "      <td>0.036421</td>\n",
       "      <td>0.165885</td>\n",
       "      <td>0.057104</td>\n",
       "      <td>-0.093255</td>\n",
       "      <td>-0.149246</td>\n",
       "      <td>-0.050350</td>\n",
       "      <td>0.122724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.085814</td>\n",
       "      <td>0.019714</td>\n",
       "      <td>0.092567</td>\n",
       "      <td>-0.046294</td>\n",
       "      <td>-0.063478</td>\n",
       "      <td>-0.012849</td>\n",
       "      <td>0.079008</td>\n",
       "      <td>0.265424</td>\n",
       "      <td>0.041190</td>\n",
       "      <td>0.084285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116445</td>\n",
       "      <td>-0.077676</td>\n",
       "      <td>-0.152492</td>\n",
       "      <td>0.058571</td>\n",
       "      <td>0.083522</td>\n",
       "      <td>0.096404</td>\n",
       "      <td>0.073179</td>\n",
       "      <td>-0.092170</td>\n",
       "      <td>-0.057123</td>\n",
       "      <td>-0.005349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.075152</td>\n",
       "      <td>0.073966</td>\n",
       "      <td>0.039749</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>-0.024459</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>-0.033008</td>\n",
       "      <td>0.212762</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.096275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>-0.101421</td>\n",
       "      <td>-0.123798</td>\n",
       "      <td>0.122955</td>\n",
       "      <td>0.101871</td>\n",
       "      <td>0.067030</td>\n",
       "      <td>-0.021039</td>\n",
       "      <td>-0.177599</td>\n",
       "      <td>-0.051054</td>\n",
       "      <td>0.047357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032002</td>\n",
       "      <td>0.120783</td>\n",
       "      <td>0.066957</td>\n",
       "      <td>-0.128963</td>\n",
       "      <td>-0.008886</td>\n",
       "      <td>-0.034391</td>\n",
       "      <td>-0.008858</td>\n",
       "      <td>0.255312</td>\n",
       "      <td>0.078952</td>\n",
       "      <td>0.094861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059976</td>\n",
       "      <td>0.025396</td>\n",
       "      <td>-0.195635</td>\n",
       "      <td>0.099526</td>\n",
       "      <td>0.057682</td>\n",
       "      <td>0.064332</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>-0.061286</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>-0.039828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.092328</td>\n",
       "      <td>0.184989</td>\n",
       "      <td>0.024131</td>\n",
       "      <td>-0.076040</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>-0.058682</td>\n",
       "      <td>-0.020498</td>\n",
       "      <td>0.225975</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>0.071678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023249</td>\n",
       "      <td>0.029947</td>\n",
       "      <td>-0.145327</td>\n",
       "      <td>0.079080</td>\n",
       "      <td>0.088762</td>\n",
       "      <td>0.089566</td>\n",
       "      <td>0.032271</td>\n",
       "      <td>-0.190924</td>\n",
       "      <td>-0.045433</td>\n",
       "      <td>-0.005441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.103260  0.164496  0.000466  0.035828 -0.014292 -0.012606 -0.057755   \n",
       "1 -0.085814  0.019714  0.092567 -0.046294 -0.063478 -0.012849  0.079008   \n",
       "2 -0.075152  0.073966  0.039749 -0.000610 -0.024459  0.001018 -0.033008   \n",
       "3  0.032002  0.120783  0.066957 -0.128963 -0.008886 -0.034391 -0.008858   \n",
       "4 -0.092328  0.184989  0.024131 -0.076040  0.028363 -0.058682 -0.020498   \n",
       "\n",
       "          7         8         9  ...       758       759       760       761  \\\n",
       "0  0.201483  0.020815  0.107380  ... -0.003843 -0.086718 -0.041593  0.036421   \n",
       "1  0.265424  0.041190  0.084285  ... -0.116445 -0.077676 -0.152492  0.058571   \n",
       "2  0.212762  0.004864  0.096275  ...  0.044050 -0.101421 -0.123798  0.122955   \n",
       "3  0.255312  0.078952  0.094861  ... -0.059976  0.025396 -0.195635  0.099526   \n",
       "4  0.225975  0.007710  0.071678  ... -0.023249  0.029947 -0.145327  0.079080   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.165885  0.057104 -0.093255 -0.149246 -0.050350  0.122724  \n",
       "1  0.083522  0.096404  0.073179 -0.092170 -0.057123 -0.005349  \n",
       "2  0.101871  0.067030 -0.021039 -0.177599 -0.051054  0.047357  \n",
       "3  0.057682  0.064332  0.017317 -0.061286  0.009324 -0.039828  \n",
       "4  0.088762  0.089566  0.032271 -0.190924 -0.045433 -0.005441  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49324192"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.to_csv(path_data + \"sentence_embeddings_CLS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.read_csv(path_data + \"sentence_embeddings_CLS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yohannlefaou/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "# one hot encode the target\n",
    "ohe = OneHotEncoder()\n",
    "one_hot_encode_labels = ohe.fit_transform(labels[\"intention\"].values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train2, one_hot_encode_labels, test_size=0.2,\n",
    "                                                      random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dropout(0.3, input_shape=(768,)))\n",
    "#nn.add(Dense(1024, input_dim= 768, activation=\"relu\")) # input_dim= 768\n",
    "#nn.add(Dropout(0.3))\n",
    "#nn.add(Dense(256, activation=\"relu\"))\n",
    "#nn.add(Dropout(0.3))\n",
    "nn.add(Dense(51, activation=\"softmax\")) #a completer\n",
    "\n",
    "nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 2s 384us/step - loss: 3.1423 - accuracy: 0.2154 - val_loss: 2.9775 - val_accuracy: 0.2335\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 2s 255us/step - loss: 2.8969 - accuracy: 0.2488 - val_loss: 2.8241 - val_accuracy: 0.2833\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 2s 266us/step - loss: 2.7528 - accuracy: 0.2867 - val_loss: 2.7028 - val_accuracy: 0.3088\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 2s 275us/step - loss: 2.6352 - accuracy: 0.3198 - val_loss: 2.6036 - val_accuracy: 0.3213\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 2s 269us/step - loss: 2.5355 - accuracy: 0.3440 - val_loss: 2.5197 - val_accuracy: 0.3624\n",
      "Epoch 6/30\n",
      "6422/6422 [==============================] - 2s 281us/step - loss: 2.4487 - accuracy: 0.3634 - val_loss: 2.4440 - val_accuracy: 0.3910\n",
      "Epoch 7/30\n",
      "6422/6422 [==============================] - 2s 277us/step - loss: 2.3714 - accuracy: 0.3930 - val_loss: 2.3805 - val_accuracy: 0.3998\n",
      "Epoch 8/30\n",
      "6422/6422 [==============================] - 2s 277us/step - loss: 2.3112 - accuracy: 0.4050 - val_loss: 2.3179 - val_accuracy: 0.4209\n",
      "Epoch 9/30\n",
      "6422/6422 [==============================] - 2s 272us/step - loss: 2.2532 - accuracy: 0.4168 - val_loss: 2.2668 - val_accuracy: 0.4359\n",
      "Epoch 10/30\n",
      "6422/6422 [==============================] - 2s 273us/step - loss: 2.1986 - accuracy: 0.4402 - val_loss: 2.2126 - val_accuracy: 0.4346\n",
      "Epoch 11/30\n",
      "6422/6422 [==============================] - 2s 292us/step - loss: 2.1452 - accuracy: 0.4430 - val_loss: 2.1655 - val_accuracy: 0.4514\n",
      "Epoch 12/30\n",
      "6422/6422 [==============================] - 2s 307us/step - loss: 2.0995 - accuracy: 0.4542 - val_loss: 2.1285 - val_accuracy: 0.4689\n",
      "Epoch 13/30\n",
      "6422/6422 [==============================] - 2s 289us/step - loss: 2.0601 - accuracy: 0.4609 - val_loss: 2.0976 - val_accuracy: 0.4745\n",
      "Epoch 14/30\n",
      "6422/6422 [==============================] - 2s 304us/step - loss: 2.0189 - accuracy: 0.4770 - val_loss: 2.0589 - val_accuracy: 0.4782\n",
      "Epoch 15/30\n",
      "6422/6422 [==============================] - 2s 271us/step - loss: 1.9907 - accuracy: 0.4801 - val_loss: 2.0320 - val_accuracy: 0.4963\n",
      "Epoch 16/30\n",
      "6422/6422 [==============================] - 2s 291us/step - loss: 1.9554 - accuracy: 0.4863 - val_loss: 1.9985 - val_accuracy: 0.5075\n",
      "Epoch 17/30\n",
      "6422/6422 [==============================] - 2s 322us/step - loss: 1.9171 - accuracy: 0.4966 - val_loss: 1.9694 - val_accuracy: 0.4913\n",
      "Epoch 18/30\n",
      "6422/6422 [==============================] - 2s 283us/step - loss: 1.8907 - accuracy: 0.5089 - val_loss: 1.9466 - val_accuracy: 0.5137\n",
      "Epoch 19/30\n",
      "6422/6422 [==============================] - 2s 277us/step - loss: 1.8609 - accuracy: 0.5117 - val_loss: 1.9209 - val_accuracy: 0.5075\n",
      "Epoch 20/30\n",
      "6422/6422 [==============================] - 2s 283us/step - loss: 1.8423 - accuracy: 0.5106 - val_loss: 1.8981 - val_accuracy: 0.5255\n",
      "Epoch 21/30\n",
      "6422/6422 [==============================] - 2s 305us/step - loss: 1.8091 - accuracy: 0.5198 - val_loss: 1.8700 - val_accuracy: 0.5143\n",
      "Epoch 22/30\n",
      "6422/6422 [==============================] - 2s 292us/step - loss: 1.7949 - accuracy: 0.5266 - val_loss: 1.8494 - val_accuracy: 0.5156\n",
      "Epoch 23/30\n",
      "6422/6422 [==============================] - 2s 286us/step - loss: 1.7662 - accuracy: 0.5299 - val_loss: 1.8330 - val_accuracy: 0.5318\n",
      "Epoch 24/30\n",
      "6422/6422 [==============================] - 2s 283us/step - loss: 1.7486 - accuracy: 0.5397 - val_loss: 1.8126 - val_accuracy: 0.5423\n",
      "Epoch 25/30\n",
      "6422/6422 [==============================] - 2s 283us/step - loss: 1.7327 - accuracy: 0.5448 - val_loss: 1.7988 - val_accuracy: 0.5286\n",
      "Epoch 26/30\n",
      "6422/6422 [==============================] - 2s 298us/step - loss: 1.7120 - accuracy: 0.5491 - val_loss: 1.7792 - val_accuracy: 0.5367\n",
      "Epoch 27/30\n",
      "6422/6422 [==============================] - 2s 282us/step - loss: 1.6929 - accuracy: 0.5522 - val_loss: 1.7603 - val_accuracy: 0.5467\n",
      "Epoch 28/30\n",
      "6422/6422 [==============================] - 2s 278us/step - loss: 1.6743 - accuracy: 0.5596 - val_loss: 1.7481 - val_accuracy: 0.5455\n",
      "Epoch 29/30\n",
      "6422/6422 [==============================] - 2s 295us/step - loss: 1.6631 - accuracy: 0.5553 - val_loss: 1.7312 - val_accuracy: 0.5567\n",
      "Epoch 30/30\n",
      "6422/6422 [==============================] - 2s 297us/step - loss: 1.6469 - accuracy: 0.5598 - val_loss: 1.7194 - val_accuracy: 0.5554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7ceb6cd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "\n",
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=32,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/10\n",
      "6422/6422 [==============================] - 2s 270us/step - loss: 1.6345 - accuracy: 0.5623 - val_loss: 1.7043 - val_accuracy: 0.5660\n",
      "Epoch 2/10\n",
      "6422/6422 [==============================] - 2s 259us/step - loss: 1.6203 - accuracy: 0.5646 - val_loss: 1.6972 - val_accuracy: 0.5573\n",
      "Epoch 3/10\n",
      "6422/6422 [==============================] - 2s 273us/step - loss: 1.5995 - accuracy: 0.5676 - val_loss: 1.6831 - val_accuracy: 0.5573\n",
      "Epoch 4/10\n",
      "6422/6422 [==============================] - 2s 281us/step - loss: 1.5910 - accuracy: 0.5744 - val_loss: 1.6700 - val_accuracy: 0.5660\n",
      "Epoch 5/10\n",
      "6422/6422 [==============================] - 2s 278us/step - loss: 1.5849 - accuracy: 0.5740 - val_loss: 1.6565 - val_accuracy: 0.5729\n",
      "Epoch 6/10\n",
      "6422/6422 [==============================] - 2s 293us/step - loss: 1.5652 - accuracy: 0.5847 - val_loss: 1.6500 - val_accuracy: 0.5654\n",
      "Epoch 7/10\n",
      "6422/6422 [==============================] - 2s 298us/step - loss: 1.5643 - accuracy: 0.5830 - val_loss: 1.6342 - val_accuracy: 0.5803\n",
      "Epoch 8/10\n",
      "6422/6422 [==============================] - 2s 282us/step - loss: 1.5454 - accuracy: 0.5877 - val_loss: 1.6276 - val_accuracy: 0.5791\n",
      "Epoch 9/10\n",
      "6422/6422 [==============================] - 2s 286us/step - loss: 1.5336 - accuracy: 0.5900 - val_loss: 1.6250 - val_accuracy: 0.5797\n",
      "Epoch 10/10\n",
      "6422/6422 [==============================] - 2s 292us/step - loss: 1.5176 - accuracy: 0.5920 - val_loss: 1.6092 - val_accuracy: 0.5822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a90f60bd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=10, batch_size=32,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/10\n",
      "6422/6422 [==============================] - 2s 269us/step - loss: 1.5098 - accuracy: 0.5944 - val_loss: 1.6079 - val_accuracy: 0.5803\n",
      "Epoch 2/10\n",
      "6422/6422 [==============================] - 2s 259us/step - loss: 1.5025 - accuracy: 0.5947 - val_loss: 1.5974 - val_accuracy: 0.5897\n",
      "Epoch 3/10\n",
      "6422/6422 [==============================] - 2s 276us/step - loss: 1.4971 - accuracy: 0.5990 - val_loss: 1.5892 - val_accuracy: 0.5890\n",
      "Epoch 4/10\n",
      "6422/6422 [==============================] - 2s 272us/step - loss: 1.4807 - accuracy: 0.5970 - val_loss: 1.5774 - val_accuracy: 0.5872\n",
      "Epoch 5/10\n",
      "6422/6422 [==============================] - 2s 274us/step - loss: 1.4776 - accuracy: 0.5987 - val_loss: 1.5765 - val_accuracy: 0.5897\n",
      "Epoch 6/10\n",
      "6422/6422 [==============================] - 2s 286us/step - loss: 1.4690 - accuracy: 0.5969 - val_loss: 1.5629 - val_accuracy: 0.5965\n",
      "Epoch 7/10\n",
      "6422/6422 [==============================] - 2s 283us/step - loss: 1.4657 - accuracy: 0.6043 - val_loss: 1.5557 - val_accuracy: 0.5959\n",
      "Epoch 8/10\n",
      "6422/6422 [==============================] - 2s 284us/step - loss: 1.4477 - accuracy: 0.6096 - val_loss: 1.5558 - val_accuracy: 0.5797\n",
      "Epoch 9/10\n",
      "6422/6422 [==============================] - 2s 266us/step - loss: 1.4364 - accuracy: 0.6148 - val_loss: 1.5486 - val_accuracy: 0.5922\n",
      "Epoch 10/10\n",
      "6422/6422 [==============================] - 2s 275us/step - loss: 1.4416 - accuracy: 0.6050 - val_loss: 1.5409 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7d300b50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=10, batch_size=32,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 1s 184us/step - loss: 1.4204 - accuracy: 0.6127 - val_loss: 1.5314 - val_accuracy: 0.5978\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 1s 176us/step - loss: 1.4233 - accuracy: 0.6106 - val_loss: 1.5261 - val_accuracy: 0.6021\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 1s 192us/step - loss: 1.4153 - accuracy: 0.6132 - val_loss: 1.5257 - val_accuracy: 0.6009\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.3998 - accuracy: 0.6159 - val_loss: 1.5252 - val_accuracy: 0.6059\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 1s 189us/step - loss: 1.4095 - accuracy: 0.6159 - val_loss: 1.5199 - val_accuracy: 0.6015\n",
      "Epoch 6/30\n",
      "6422/6422 [==============================] - 1s 199us/step - loss: 1.4098 - accuracy: 0.6177 - val_loss: 1.5148 - val_accuracy: 0.6021\n",
      "Epoch 7/30\n",
      "6422/6422 [==============================] - 1s 191us/step - loss: 1.4031 - accuracy: 0.6174 - val_loss: 1.5116 - val_accuracy: 0.6059\n",
      "Epoch 8/30\n",
      "6422/6422 [==============================] - 1s 207us/step - loss: 1.3935 - accuracy: 0.6174 - val_loss: 1.5080 - val_accuracy: 0.6034\n",
      "Epoch 9/30\n",
      "6422/6422 [==============================] - 1s 189us/step - loss: 1.3911 - accuracy: 0.6205 - val_loss: 1.5061 - val_accuracy: 0.6046\n",
      "Epoch 10/30\n",
      "6422/6422 [==============================] - 1s 191us/step - loss: 1.3831 - accuracy: 0.6207 - val_loss: 1.4994 - val_accuracy: 0.6102\n",
      "Epoch 11/30\n",
      "6422/6422 [==============================] - 1s 197us/step - loss: 1.3873 - accuracy: 0.6191 - val_loss: 1.4999 - val_accuracy: 0.6071\n",
      "Epoch 12/30\n",
      "6422/6422 [==============================] - 1s 206us/step - loss: 1.3816 - accuracy: 0.6211 - val_loss: 1.4968 - val_accuracy: 0.6071\n",
      "Epoch 13/30\n",
      "6422/6422 [==============================] - 1s 196us/step - loss: 1.3801 - accuracy: 0.6227 - val_loss: 1.4956 - val_accuracy: 0.6071\n",
      "Epoch 14/30\n",
      "6422/6422 [==============================] - 1s 189us/step - loss: 1.3678 - accuracy: 0.6257 - val_loss: 1.4922 - val_accuracy: 0.6021\n",
      "Epoch 15/30\n",
      "6422/6422 [==============================] - 1s 191us/step - loss: 1.3853 - accuracy: 0.6191 - val_loss: 1.4891 - val_accuracy: 0.6052\n",
      "Epoch 16/30\n",
      "6422/6422 [==============================] - 1s 206us/step - loss: 1.3753 - accuracy: 0.6233 - val_loss: 1.4859 - val_accuracy: 0.6139\n",
      "Epoch 17/30\n",
      "6422/6422 [==============================] - 1s 195us/step - loss: 1.3656 - accuracy: 0.6291 - val_loss: 1.4798 - val_accuracy: 0.6090\n",
      "Epoch 18/30\n",
      "3008/6422 [=============>................] - ETA: 0s - loss: 1.3688 - accuracy: 0.6223"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-eff427bdc5ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m nn.fit(np.array(X_train), y_train, epochs=30, batch_size=64,\n\u001b[0;32m----> 2\u001b[0;31m        validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=64,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/5\n",
      "6422/6422 [==============================] - 1s 136us/step - loss: 1.3696 - accuracy: 0.6236 - val_loss: 1.4747 - val_accuracy: 0.6108\n",
      "Epoch 2/5\n",
      "6422/6422 [==============================] - 1s 142us/step - loss: 1.3528 - accuracy: 0.6252 - val_loss: 1.4732 - val_accuracy: 0.6133\n",
      "Epoch 3/5\n",
      "6422/6422 [==============================] - 1s 142us/step - loss: 1.3469 - accuracy: 0.6291 - val_loss: 1.4717 - val_accuracy: 0.6152\n",
      "Epoch 4/5\n",
      "6422/6422 [==============================] - 1s 144us/step - loss: 1.3504 - accuracy: 0.6207 - val_loss: 1.4699 - val_accuracy: 0.6146\n",
      "Epoch 5/5\n",
      "6422/6422 [==============================] - 1s 146us/step - loss: 1.3510 - accuracy: 0.6314 - val_loss: 1.4677 - val_accuracy: 0.6158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a90f53250>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=20, batch_size=128,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/20\n",
      "6422/6422 [==============================] - 1s 134us/step - loss: 1.3468 - accuracy: 0.6277 - val_loss: 1.4690 - val_accuracy: 0.6171\n",
      "Epoch 2/20\n",
      "6422/6422 [==============================] - 1s 144us/step - loss: 1.3401 - accuracy: 0.6322 - val_loss: 1.4685 - val_accuracy: 0.6146\n",
      "Epoch 3/20\n",
      "6422/6422 [==============================] - 1s 155us/step - loss: 1.3396 - accuracy: 0.6294 - val_loss: 1.4653 - val_accuracy: 0.6133\n",
      "Epoch 4/20\n",
      "6422/6422 [==============================] - 1s 142us/step - loss: 1.3395 - accuracy: 0.6341 - val_loss: 1.4639 - val_accuracy: 0.6133\n",
      "Epoch 5/20\n",
      "6422/6422 [==============================] - 1s 148us/step - loss: 1.3429 - accuracy: 0.6289 - val_loss: 1.4623 - val_accuracy: 0.6202\n",
      "Epoch 6/20\n",
      "6422/6422 [==============================] - 1s 151us/step - loss: 1.3393 - accuracy: 0.6274 - val_loss: 1.4616 - val_accuracy: 0.6121\n",
      "Epoch 7/20\n",
      "6422/6422 [==============================] - 1s 148us/step - loss: 1.3412 - accuracy: 0.6330 - val_loss: 1.4608 - val_accuracy: 0.6164\n",
      "Epoch 8/20\n",
      "6422/6422 [==============================] - 1s 149us/step - loss: 1.3344 - accuracy: 0.6328 - val_loss: 1.4591 - val_accuracy: 0.6164\n",
      "Epoch 9/20\n",
      "6422/6422 [==============================] - 1s 155us/step - loss: 1.3343 - accuracy: 0.6328 - val_loss: 1.4555 - val_accuracy: 0.6164\n",
      "Epoch 10/20\n",
      "6422/6422 [==============================] - 1s 141us/step - loss: 1.3399 - accuracy: 0.6299 - val_loss: 1.4549 - val_accuracy: 0.6208\n",
      "Epoch 11/20\n",
      "6422/6422 [==============================] - 1s 149us/step - loss: 1.3307 - accuracy: 0.6392 - val_loss: 1.4548 - val_accuracy: 0.6177\n",
      "Epoch 12/20\n",
      "6422/6422 [==============================] - 1s 146us/step - loss: 1.3371 - accuracy: 0.6260 - val_loss: 1.4520 - val_accuracy: 0.6158\n",
      "Epoch 13/20\n",
      "6422/6422 [==============================] - 1s 147us/step - loss: 1.3251 - accuracy: 0.6342 - val_loss: 1.4504 - val_accuracy: 0.6146\n",
      "Epoch 14/20\n",
      "6422/6422 [==============================] - 1s 160us/step - loss: 1.3319 - accuracy: 0.6333 - val_loss: 1.4491 - val_accuracy: 0.6152\n",
      "Epoch 15/20\n",
      "6422/6422 [==============================] - 1s 150us/step - loss: 1.3202 - accuracy: 0.6345 - val_loss: 1.4502 - val_accuracy: 0.6227\n",
      "Epoch 16/20\n",
      "6422/6422 [==============================] - 1s 148us/step - loss: 1.3140 - accuracy: 0.6372 - val_loss: 1.4466 - val_accuracy: 0.6208\n",
      "Epoch 17/20\n",
      "6422/6422 [==============================] - 1s 141us/step - loss: 1.3114 - accuracy: 0.6401 - val_loss: 1.4438 - val_accuracy: 0.6152\n",
      "Epoch 18/20\n",
      "6422/6422 [==============================] - 1s 150us/step - loss: 1.3199 - accuracy: 0.6322 - val_loss: 1.4429 - val_accuracy: 0.6208\n",
      "Epoch 19/20\n",
      "6422/6422 [==============================] - 1s 160us/step - loss: 1.3189 - accuracy: 0.6386 - val_loss: 1.4435 - val_accuracy: 0.6171\n",
      "Epoch 20/20\n",
      "6422/6422 [==============================] - 1s 160us/step - loss: 1.3098 - accuracy: 0.6367 - val_loss: 1.4374 - val_accuracy: 0.6214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7d1bd750>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=20, batch_size=128,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dropout(0.1, input_shape=(768,)))\n",
    "#nn.add(Dense(1024, input_dim= 768, activation=\"relu\")) # input_dim= 768\n",
    "#nn.add(Dropout(0.3))\n",
    "#nn.add(Dense(256, activation=\"relu\"))\n",
    "#nn.add(Dropout(0.3))\n",
    "nn.add(Dense(51, activation=\"softmax\")) #a completer\n",
    "\n",
    "nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 2s 328us/step - loss: 3.2134 - accuracy: 0.1950 - val_loss: 3.0310 - val_accuracy: 0.2316\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 1s 192us/step - loss: 2.9575 - accuracy: 0.2270 - val_loss: 2.9050 - val_accuracy: 0.2522\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 1s 190us/step - loss: 2.8367 - accuracy: 0.2565 - val_loss: 2.8033 - val_accuracy: 0.2534\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 2.7333 - accuracy: 0.2846 - val_loss: 2.7175 - val_accuracy: 0.3001\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 1s 192us/step - loss: 2.6436 - accuracy: 0.3078 - val_loss: 2.6314 - val_accuracy: 0.3182\n",
      "Epoch 6/30\n",
      "6422/6422 [==============================] - 1s 210us/step - loss: 2.5600 - accuracy: 0.3306 - val_loss: 2.5628 - val_accuracy: 0.3618\n",
      "Epoch 7/30\n",
      "6422/6422 [==============================] - 1s 199us/step - loss: 2.4881 - accuracy: 0.3563 - val_loss: 2.4961 - val_accuracy: 0.3493\n",
      "Epoch 8/30\n",
      "6422/6422 [==============================] - 1s 201us/step - loss: 2.4239 - accuracy: 0.3720 - val_loss: 2.4403 - val_accuracy: 0.3798\n",
      "Epoch 9/30\n",
      "6422/6422 [==============================] - 1s 199us/step - loss: 2.3643 - accuracy: 0.3887 - val_loss: 2.3825 - val_accuracy: 0.3948\n",
      "Epoch 10/30\n",
      "6422/6422 [==============================] - 1s 196us/step - loss: 2.3063 - accuracy: 0.4041 - val_loss: 2.3390 - val_accuracy: 0.4172\n",
      "Epoch 11/30\n",
      "6422/6422 [==============================] - 1s 198us/step - loss: 2.2520 - accuracy: 0.4209 - val_loss: 2.2940 - val_accuracy: 0.4191\n",
      "Epoch 12/30\n",
      "6422/6422 [==============================] - 1s 192us/step - loss: 2.2069 - accuracy: 0.4324 - val_loss: 2.2505 - val_accuracy: 0.4265\n",
      "Epoch 13/30\n",
      "6422/6422 [==============================] - 1s 205us/step - loss: 2.1629 - accuracy: 0.4439 - val_loss: 2.2096 - val_accuracy: 0.4514\n",
      "Epoch 14/30\n",
      "6422/6422 [==============================] - 1s 212us/step - loss: 2.1251 - accuracy: 0.4533 - val_loss: 2.1754 - val_accuracy: 0.4533\n",
      "Epoch 15/30\n",
      "6422/6422 [==============================] - 1s 203us/step - loss: 2.0829 - accuracy: 0.4631 - val_loss: 2.1435 - val_accuracy: 0.4757\n",
      "Epoch 16/30\n",
      "6422/6422 [==============================] - 1s 193us/step - loss: 2.0451 - accuracy: 0.4743 - val_loss: 2.1133 - val_accuracy: 0.4682\n",
      "Epoch 17/30\n",
      "6422/6422 [==============================] - 1s 208us/step - loss: 2.0175 - accuracy: 0.4768 - val_loss: 2.0859 - val_accuracy: 0.4894\n",
      "Epoch 18/30\n",
      "6422/6422 [==============================] - 1s 199us/step - loss: 1.9791 - accuracy: 0.4851 - val_loss: 2.0555 - val_accuracy: 0.4851\n",
      "Epoch 19/30\n",
      "6422/6422 [==============================] - 1s 197us/step - loss: 1.9525 - accuracy: 0.4958 - val_loss: 2.0310 - val_accuracy: 0.4844\n",
      "Epoch 20/30\n",
      "6422/6422 [==============================] - 1s 201us/step - loss: 1.9198 - accuracy: 0.5014 - val_loss: 2.0051 - val_accuracy: 0.4938\n",
      "Epoch 21/30\n",
      "6422/6422 [==============================] - 1s 196us/step - loss: 1.8902 - accuracy: 0.5083 - val_loss: 1.9788 - val_accuracy: 0.5031\n",
      "Epoch 22/30\n",
      "6422/6422 [==============================] - 1s 198us/step - loss: 1.8650 - accuracy: 0.5095 - val_loss: 1.9583 - val_accuracy: 0.5181\n",
      "Epoch 23/30\n",
      "6422/6422 [==============================] - 1s 194us/step - loss: 1.8441 - accuracy: 0.5202 - val_loss: 1.9383 - val_accuracy: 0.5131\n",
      "Epoch 24/30\n",
      "6422/6422 [==============================] - 1s 208us/step - loss: 1.8178 - accuracy: 0.5221 - val_loss: 1.9166 - val_accuracy: 0.5037\n",
      "Epoch 25/30\n",
      "6422/6422 [==============================] - 1s 202us/step - loss: 1.7896 - accuracy: 0.5287 - val_loss: 1.8964 - val_accuracy: 0.5168\n",
      "Epoch 26/30\n",
      "6422/6422 [==============================] - 1s 201us/step - loss: 1.7725 - accuracy: 0.5360 - val_loss: 1.8731 - val_accuracy: 0.5243\n",
      "Epoch 27/30\n",
      "6422/6422 [==============================] - 1s 221us/step - loss: 1.7489 - accuracy: 0.5425 - val_loss: 1.8564 - val_accuracy: 0.5125\n",
      "Epoch 28/30\n",
      "6422/6422 [==============================] - 1s 193us/step - loss: 1.7303 - accuracy: 0.5445 - val_loss: 1.8417 - val_accuracy: 0.5262\n",
      "Epoch 29/30\n",
      "6422/6422 [==============================] - 1s 197us/step - loss: 1.7126 - accuracy: 0.5515 - val_loss: 1.8256 - val_accuracy: 0.5399\n",
      "Epoch 30/30\n",
      "6422/6422 [==============================] - 1s 230us/step - loss: 1.6972 - accuracy: 0.5592 - val_loss: 1.8074 - val_accuracy: 0.5367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a8ff49c10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "\n",
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=64,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 1s 194us/step - loss: 1.6768 - accuracy: 0.5587 - val_loss: 1.7940 - val_accuracy: 0.5293\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 1s 194us/step - loss: 1.6556 - accuracy: 0.5631 - val_loss: 1.7844 - val_accuracy: 0.5380\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 1s 194us/step - loss: 1.6419 - accuracy: 0.5682 - val_loss: 1.7633 - val_accuracy: 0.5417\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 1s 197us/step - loss: 1.6233 - accuracy: 0.5741 - val_loss: 1.7560 - val_accuracy: 0.5492\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 1s 200us/step - loss: 1.6079 - accuracy: 0.5761 - val_loss: 1.7429 - val_accuracy: 0.5535\n",
      "Epoch 6/30\n",
      "6422/6422 [==============================] - 1s 192us/step - loss: 1.5967 - accuracy: 0.5846 - val_loss: 1.7264 - val_accuracy: 0.5486\n",
      "Epoch 7/30\n",
      "6422/6422 [==============================] - 1s 204us/step - loss: 1.5784 - accuracy: 0.5853 - val_loss: 1.7154 - val_accuracy: 0.5573\n",
      "Epoch 8/30\n",
      "6422/6422 [==============================] - 1s 196us/step - loss: 1.5673 - accuracy: 0.5891 - val_loss: 1.7041 - val_accuracy: 0.5573\n",
      "Epoch 9/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.5558 - accuracy: 0.5866 - val_loss: 1.6938 - val_accuracy: 0.5654\n",
      "Epoch 10/30\n",
      "6422/6422 [==============================] - 1s 185us/step - loss: 1.5384 - accuracy: 0.5975 - val_loss: 1.6804 - val_accuracy: 0.5760\n",
      "Epoch 11/30\n",
      "6422/6422 [==============================] - 1s 191us/step - loss: 1.5270 - accuracy: 0.6007 - val_loss: 1.6690 - val_accuracy: 0.5666\n",
      "Epoch 12/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.5098 - accuracy: 0.6054 - val_loss: 1.6588 - val_accuracy: 0.5716\n",
      "Epoch 13/30\n",
      "6422/6422 [==============================] - 1s 220us/step - loss: 1.5005 - accuracy: 0.6050 - val_loss: 1.6498 - val_accuracy: 0.5722\n",
      "Epoch 14/30\n",
      "6422/6422 [==============================] - 1s 192us/step - loss: 1.4980 - accuracy: 0.6037 - val_loss: 1.6398 - val_accuracy: 0.5816\n",
      "Epoch 15/30\n",
      "6422/6422 [==============================] - 1s 190us/step - loss: 1.4785 - accuracy: 0.6067 - val_loss: 1.6300 - val_accuracy: 0.5866\n",
      "Epoch 16/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.4719 - accuracy: 0.6102 - val_loss: 1.6197 - val_accuracy: 0.5834\n",
      "Epoch 17/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.4574 - accuracy: 0.6168 - val_loss: 1.6179 - val_accuracy: 0.5772\n",
      "Epoch 18/30\n",
      "6422/6422 [==============================] - 1s 191us/step - loss: 1.4445 - accuracy: 0.6171 - val_loss: 1.6099 - val_accuracy: 0.5903\n",
      "Epoch 19/30\n",
      "6422/6422 [==============================] - 1s 187us/step - loss: 1.4357 - accuracy: 0.6191 - val_loss: 1.6012 - val_accuracy: 0.5903\n",
      "Epoch 20/30\n",
      "6422/6422 [==============================] - 1s 196us/step - loss: 1.4262 - accuracy: 0.6191 - val_loss: 1.5940 - val_accuracy: 0.5928\n",
      "Epoch 21/30\n",
      "6422/6422 [==============================] - 1s 199us/step - loss: 1.4140 - accuracy: 0.6268 - val_loss: 1.5778 - val_accuracy: 0.5996\n",
      "Epoch 22/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.4112 - accuracy: 0.6210 - val_loss: 1.5741 - val_accuracy: 0.5990\n",
      "Epoch 23/30\n",
      "6422/6422 [==============================] - 1s 197us/step - loss: 1.3978 - accuracy: 0.6367 - val_loss: 1.5661 - val_accuracy: 0.5897\n",
      "Epoch 24/30\n",
      "6422/6422 [==============================] - 1s 189us/step - loss: 1.3874 - accuracy: 0.6310 - val_loss: 1.5614 - val_accuracy: 0.5996\n",
      "Epoch 25/30\n",
      "6422/6422 [==============================] - 1s 200us/step - loss: 1.3806 - accuracy: 0.6358 - val_loss: 1.5567 - val_accuracy: 0.5971\n",
      "Epoch 26/30\n",
      "6422/6422 [==============================] - 1s 192us/step - loss: 1.3741 - accuracy: 0.6345 - val_loss: 1.5475 - val_accuracy: 0.5928\n",
      "Epoch 27/30\n",
      "6422/6422 [==============================] - 1s 194us/step - loss: 1.3579 - accuracy: 0.6375 - val_loss: 1.5415 - val_accuracy: 0.5953\n",
      "Epoch 28/30\n",
      "6422/6422 [==============================] - 1s 199us/step - loss: 1.3584 - accuracy: 0.6377 - val_loss: 1.5392 - val_accuracy: 0.6015\n",
      "Epoch 29/30\n",
      "6422/6422 [==============================] - 1s 197us/step - loss: 1.3437 - accuracy: 0.6426 - val_loss: 1.5290 - val_accuracy: 0.6034\n",
      "Epoch 30/30\n",
      "6422/6422 [==============================] - 1s 193us/step - loss: 1.3394 - accuracy: 0.6454 - val_loss: 1.5236 - val_accuracy: 0.6021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7d1bd690>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=64,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 1s 174us/step - loss: 1.3342 - accuracy: 0.6453 - val_loss: 1.5192 - val_accuracy: 0.5990\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 1s 178us/step - loss: 1.3257 - accuracy: 0.6450 - val_loss: 1.5109 - val_accuracy: 0.6077\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 1s 187us/step - loss: 1.3244 - accuracy: 0.6512 - val_loss: 1.5100 - val_accuracy: 0.6021\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 1s 181us/step - loss: 1.3088 - accuracy: 0.6500 - val_loss: 1.5040 - val_accuracy: 0.5984\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 1s 192us/step - loss: 1.3064 - accuracy: 0.6529 - val_loss: 1.5018 - val_accuracy: 0.6121\n",
      "Epoch 6/30\n",
      "6422/6422 [==============================] - 1s 181us/step - loss: 1.2997 - accuracy: 0.6501 - val_loss: 1.4917 - val_accuracy: 0.6108\n",
      "Epoch 7/30\n",
      "6422/6422 [==============================] - 1s 198us/step - loss: 1.2850 - accuracy: 0.6562 - val_loss: 1.4902 - val_accuracy: 0.6071\n",
      "Epoch 8/30\n",
      "6422/6422 [==============================] - 1s 203us/step - loss: 1.2849 - accuracy: 0.6535 - val_loss: 1.4864 - val_accuracy: 0.6083\n",
      "Epoch 9/30\n",
      "6422/6422 [==============================] - 1s 218us/step - loss: 1.2832 - accuracy: 0.6552 - val_loss: 1.4754 - val_accuracy: 0.6133\n",
      "Epoch 10/30\n",
      "6422/6422 [==============================] - 1s 187us/step - loss: 1.2821 - accuracy: 0.6535 - val_loss: 1.4727 - val_accuracy: 0.6133\n",
      "Epoch 11/30\n",
      "6422/6422 [==============================] - 1s 182us/step - loss: 1.2661 - accuracy: 0.6641 - val_loss: 1.4677 - val_accuracy: 0.6115\n",
      "Epoch 12/30\n",
      "6422/6422 [==============================] - 1s 192us/step - loss: 1.2563 - accuracy: 0.6632 - val_loss: 1.4654 - val_accuracy: 0.6183\n",
      "Epoch 13/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.2483 - accuracy: 0.6655 - val_loss: 1.4615 - val_accuracy: 0.6164\n",
      "Epoch 14/30\n",
      "6422/6422 [==============================] - 1s 191us/step - loss: 1.2479 - accuracy: 0.6610 - val_loss: 1.4558 - val_accuracy: 0.6127\n",
      "Epoch 15/30\n",
      "6422/6422 [==============================] - 1s 200us/step - loss: 1.2461 - accuracy: 0.6618 - val_loss: 1.4544 - val_accuracy: 0.6183\n",
      "Epoch 16/30\n",
      "6422/6422 [==============================] - 1s 187us/step - loss: 1.2410 - accuracy: 0.6652 - val_loss: 1.4465 - val_accuracy: 0.6152\n",
      "Epoch 17/30\n",
      "6422/6422 [==============================] - 1s 198us/step - loss: 1.2295 - accuracy: 0.6694 - val_loss: 1.4473 - val_accuracy: 0.6152\n",
      "Epoch 18/30\n",
      "6422/6422 [==============================] - 1s 194us/step - loss: 1.2313 - accuracy: 0.6674 - val_loss: 1.4405 - val_accuracy: 0.6202\n",
      "Epoch 19/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.2166 - accuracy: 0.6764 - val_loss: 1.4374 - val_accuracy: 0.6202\n",
      "Epoch 20/30\n",
      "6422/6422 [==============================] - 1s 189us/step - loss: 1.2147 - accuracy: 0.6713 - val_loss: 1.4319 - val_accuracy: 0.6183\n",
      "Epoch 21/30\n",
      "6422/6422 [==============================] - 1s 194us/step - loss: 1.2131 - accuracy: 0.6705 - val_loss: 1.4284 - val_accuracy: 0.6171\n",
      "Epoch 22/30\n",
      "6422/6422 [==============================] - 1s 206us/step - loss: 1.2065 - accuracy: 0.6733 - val_loss: 1.4267 - val_accuracy: 0.6139\n",
      "Epoch 23/30\n",
      "6422/6422 [==============================] - 1s 193us/step - loss: 1.1986 - accuracy: 0.6781 - val_loss: 1.4222 - val_accuracy: 0.6220\n",
      "Epoch 24/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.1965 - accuracy: 0.6769 - val_loss: 1.4251 - val_accuracy: 0.6370\n",
      "Epoch 25/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.1929 - accuracy: 0.6763 - val_loss: 1.4163 - val_accuracy: 0.6233\n",
      "Epoch 26/30\n",
      "6422/6422 [==============================] - 1s 197us/step - loss: 1.1862 - accuracy: 0.6755 - val_loss: 1.4145 - val_accuracy: 0.6264\n",
      "Epoch 27/30\n",
      "6422/6422 [==============================] - 1s 205us/step - loss: 1.1821 - accuracy: 0.6786 - val_loss: 1.4193 - val_accuracy: 0.6239\n",
      "Epoch 28/30\n",
      "6422/6422 [==============================] - 1s 188us/step - loss: 1.1788 - accuracy: 0.6828 - val_loss: 1.4082 - val_accuracy: 0.6276\n",
      "Epoch 29/30\n",
      "6422/6422 [==============================] - 1s 194us/step - loss: 1.1727 - accuracy: 0.6836 - val_loss: 1.4031 - val_accuracy: 0.6208\n",
      "Epoch 30/30\n",
      "6422/6422 [==============================] - 1s 203us/step - loss: 1.1666 - accuracy: 0.6847 - val_loss: 1.3993 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7d0dbad0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=64,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 1s 126us/step - loss: 1.1607 - accuracy: 0.6898 - val_loss: 1.3960 - val_accuracy: 0.6283\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 1s 131us/step - loss: 1.1616 - accuracy: 0.6856 - val_loss: 1.3959 - val_accuracy: 0.6295\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 1s 136us/step - loss: 1.1552 - accuracy: 0.6823 - val_loss: 1.3941 - val_accuracy: 0.6308\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 1s 147us/step - loss: 1.1548 - accuracy: 0.6867 - val_loss: 1.3900 - val_accuracy: 0.6308\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 1s 147us/step - loss: 1.1538 - accuracy: 0.6839 - val_loss: 1.3905 - val_accuracy: 0.6333\n",
      "Epoch 6/30\n",
      "6422/6422 [==============================] - 1s 185us/step - loss: 1.1527 - accuracy: 0.6819 - val_loss: 1.3894 - val_accuracy: 0.6295\n",
      "Epoch 7/30\n",
      "6422/6422 [==============================] - 1s 179us/step - loss: 1.1455 - accuracy: 0.6901 - val_loss: 1.3899 - val_accuracy: 0.6301\n",
      "Epoch 8/30\n",
      "6422/6422 [==============================] - 1s 144us/step - loss: 1.1458 - accuracy: 0.6890 - val_loss: 1.3865 - val_accuracy: 0.6308\n",
      "Epoch 9/30\n",
      "6422/6422 [==============================] - 1s 143us/step - loss: 1.1445 - accuracy: 0.6878 - val_loss: 1.3878 - val_accuracy: 0.6252\n",
      "Epoch 10/30\n",
      "6422/6422 [==============================] - 1s 146us/step - loss: 1.1413 - accuracy: 0.6847 - val_loss: 1.3851 - val_accuracy: 0.6276\n",
      "Epoch 11/30\n",
      "6422/6422 [==============================] - 1s 144us/step - loss: 1.1393 - accuracy: 0.6892 - val_loss: 1.3816 - val_accuracy: 0.6320\n",
      "Epoch 12/30\n",
      "6422/6422 [==============================] - 1s 144us/step - loss: 1.1350 - accuracy: 0.6953 - val_loss: 1.3806 - val_accuracy: 0.6308\n",
      "Epoch 13/30\n",
      "6422/6422 [==============================] - 1s 140us/step - loss: 1.1315 - accuracy: 0.6968 - val_loss: 1.3794 - val_accuracy: 0.6320\n",
      "Epoch 14/30\n",
      "6422/6422 [==============================] - 1s 148us/step - loss: 1.1308 - accuracy: 0.6925 - val_loss: 1.3782 - val_accuracy: 0.6301\n",
      "Epoch 15/30\n",
      "6422/6422 [==============================] - 1s 146us/step - loss: 1.1267 - accuracy: 0.6936 - val_loss: 1.3757 - val_accuracy: 0.6333\n",
      "Epoch 16/30\n",
      "6422/6422 [==============================] - 1s 138us/step - loss: 1.1257 - accuracy: 0.6950 - val_loss: 1.3737 - val_accuracy: 0.6301\n",
      "Epoch 17/30\n",
      "6422/6422 [==============================] - 1s 148us/step - loss: 1.1296 - accuracy: 0.6936 - val_loss: 1.3743 - val_accuracy: 0.6326\n",
      "Epoch 18/30\n",
      "6422/6422 [==============================] - 1s 161us/step - loss: 1.1201 - accuracy: 0.6974 - val_loss: 1.3710 - val_accuracy: 0.6364\n",
      "Epoch 19/30\n",
      "6422/6422 [==============================] - 1s 151us/step - loss: 1.1190 - accuracy: 0.6948 - val_loss: 1.3716 - val_accuracy: 0.6364\n",
      "Epoch 20/30\n",
      "6422/6422 [==============================] - 1s 149us/step - loss: 1.1175 - accuracy: 0.6914 - val_loss: 1.3708 - val_accuracy: 0.6370\n",
      "Epoch 21/30\n",
      "6422/6422 [==============================] - 1s 148us/step - loss: 1.1124 - accuracy: 0.6988 - val_loss: 1.3698 - val_accuracy: 0.6351\n",
      "Epoch 22/30\n",
      "6422/6422 [==============================] - 1s 147us/step - loss: 1.1150 - accuracy: 0.6985 - val_loss: 1.3660 - val_accuracy: 0.6295\n",
      "Epoch 23/30\n",
      "6422/6422 [==============================] - 1s 146us/step - loss: 1.1133 - accuracy: 0.7020 - val_loss: 1.3658 - val_accuracy: 0.6270\n",
      "Epoch 24/30\n",
      "6422/6422 [==============================] - 1s 144us/step - loss: 1.1109 - accuracy: 0.6953 - val_loss: 1.3670 - val_accuracy: 0.6395\n",
      "Epoch 25/30\n",
      "6422/6422 [==============================] - 1s 154us/step - loss: 1.1082 - accuracy: 0.6974 - val_loss: 1.3641 - val_accuracy: 0.6295\n",
      "Epoch 26/30\n",
      "6422/6422 [==============================] - 1s 153us/step - loss: 1.1022 - accuracy: 0.7012 - val_loss: 1.3628 - val_accuracy: 0.6345\n",
      "Epoch 27/30\n",
      "6422/6422 [==============================] - 1s 159us/step - loss: 1.1019 - accuracy: 0.6974 - val_loss: 1.3628 - val_accuracy: 0.6295\n",
      "Epoch 28/30\n",
      "6422/6422 [==============================] - 1s 155us/step - loss: 1.0997 - accuracy: 0.6988 - val_loss: 1.3599 - val_accuracy: 0.6345\n",
      "Epoch 29/30\n",
      "6422/6422 [==============================] - 1s 148us/step - loss: 1.0982 - accuracy: 0.6948 - val_loss: 1.3578 - val_accuracy: 0.6407\n",
      "Epoch 30/30\n",
      "6422/6422 [==============================] - 1s 153us/step - loss: 1.0941 - accuracy: 0.6962 - val_loss: 1.3541 - val_accuracy: 0.6420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7efb1d90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=124,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 1s 98us/step - loss: 1.0944 - accuracy: 0.6993 - val_loss: 1.3555 - val_accuracy: 0.6364\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 1s 109us/step - loss: 1.0851 - accuracy: 0.6990 - val_loss: 1.3562 - val_accuracy: 0.6413\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 1s 108us/step - loss: 1.0895 - accuracy: 0.7065 - val_loss: 1.3547 - val_accuracy: 0.6376\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 1s 121us/step - loss: 1.0922 - accuracy: 0.7007 - val_loss: 1.3535 - val_accuracy: 0.6357\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 1s 119us/step - loss: 1.0834 - accuracy: 0.6998 - val_loss: 1.3529 - val_accuracy: 0.6389\n",
      "Epoch 6/30\n",
      "6422/6422 [==============================] - 1s 114us/step - loss: 1.0900 - accuracy: 0.7009 - val_loss: 1.3526 - val_accuracy: 0.6413\n",
      "Epoch 7/30\n",
      "6422/6422 [==============================] - 1s 112us/step - loss: 1.0805 - accuracy: 0.7035 - val_loss: 1.3508 - val_accuracy: 0.6382\n",
      "Epoch 8/30\n",
      "6422/6422 [==============================] - 1s 115us/step - loss: 1.0853 - accuracy: 0.7012 - val_loss: 1.3517 - val_accuracy: 0.6395\n",
      "Epoch 9/30\n",
      "6422/6422 [==============================] - 1s 109us/step - loss: 1.0780 - accuracy: 0.7043 - val_loss: 1.3512 - val_accuracy: 0.6401\n",
      "Epoch 10/30\n",
      "6422/6422 [==============================] - 1s 114us/step - loss: 1.0804 - accuracy: 0.7034 - val_loss: 1.3491 - val_accuracy: 0.6357\n",
      "Epoch 11/30\n",
      "6422/6422 [==============================] - 1s 110us/step - loss: 1.0812 - accuracy: 0.7017 - val_loss: 1.3488 - val_accuracy: 0.6451\n",
      "Epoch 12/30\n",
      "6422/6422 [==============================] - 1s 110us/step - loss: 1.0782 - accuracy: 0.7049 - val_loss: 1.3474 - val_accuracy: 0.6364\n",
      "Epoch 13/30\n",
      "6422/6422 [==============================] - 1s 120us/step - loss: 1.0740 - accuracy: 0.7079 - val_loss: 1.3493 - val_accuracy: 0.6382\n",
      "Epoch 14/30\n",
      "6422/6422 [==============================] - 1s 116us/step - loss: 1.0724 - accuracy: 0.7083 - val_loss: 1.3484 - val_accuracy: 0.6389\n",
      "Epoch 15/30\n",
      "6422/6422 [==============================] - 1s 111us/step - loss: 1.0730 - accuracy: 0.7093 - val_loss: 1.3475 - val_accuracy: 0.6370\n",
      "Epoch 16/30\n",
      "6422/6422 [==============================] - 1s 112us/step - loss: 1.0703 - accuracy: 0.7094 - val_loss: 1.3460 - val_accuracy: 0.6370\n",
      "Epoch 17/30\n",
      "6422/6422 [==============================] - 1s 112us/step - loss: 1.0707 - accuracy: 0.7096 - val_loss: 1.3462 - val_accuracy: 0.6457\n",
      "Epoch 18/30\n",
      "6422/6422 [==============================] - 1s 115us/step - loss: 1.0723 - accuracy: 0.7105 - val_loss: 1.3448 - val_accuracy: 0.6351\n",
      "Epoch 19/30\n",
      "6422/6422 [==============================] - 1s 112us/step - loss: 1.0743 - accuracy: 0.7063 - val_loss: 1.3434 - val_accuracy: 0.6389\n",
      "Epoch 20/30\n",
      "6422/6422 [==============================] - 1s 111us/step - loss: 1.0642 - accuracy: 0.7085 - val_loss: 1.3442 - val_accuracy: 0.6351\n",
      "Epoch 21/30\n",
      "6422/6422 [==============================] - 1s 111us/step - loss: 1.0665 - accuracy: 0.7099 - val_loss: 1.3421 - val_accuracy: 0.6407\n",
      "Epoch 22/30\n",
      "6422/6422 [==============================] - 1s 114us/step - loss: 1.0689 - accuracy: 0.7080 - val_loss: 1.3416 - val_accuracy: 0.6407\n",
      "Epoch 23/30\n",
      "6422/6422 [==============================] - 1s 113us/step - loss: 1.0666 - accuracy: 0.7060 - val_loss: 1.3420 - val_accuracy: 0.6445\n",
      "Epoch 24/30\n",
      "6422/6422 [==============================] - 1s 114us/step - loss: 1.0633 - accuracy: 0.7116 - val_loss: 1.3404 - val_accuracy: 0.6401\n",
      "Epoch 25/30\n",
      "6422/6422 [==============================] - 1s 119us/step - loss: 1.0649 - accuracy: 0.7088 - val_loss: 1.3402 - val_accuracy: 0.6438\n",
      "Epoch 26/30\n",
      "6422/6422 [==============================] - 1s 114us/step - loss: 1.0596 - accuracy: 0.7071 - val_loss: 1.3394 - val_accuracy: 0.6413\n",
      "Epoch 27/30\n",
      "6422/6422 [==============================] - 1s 115us/step - loss: 1.0602 - accuracy: 0.7105 - val_loss: 1.3373 - val_accuracy: 0.6438\n",
      "Epoch 28/30\n",
      "6422/6422 [==============================] - 1s 113us/step - loss: 1.0568 - accuracy: 0.7097 - val_loss: 1.3397 - val_accuracy: 0.6407\n",
      "Epoch 29/30\n",
      "6422/6422 [==============================] - 1s 112us/step - loss: 1.0560 - accuracy: 0.7074 - val_loss: 1.3393 - val_accuracy: 0.6432\n",
      "Epoch 30/30\n",
      "6422/6422 [==============================] - 1s 119us/step - loss: 1.0532 - accuracy: 0.7126 - val_loss: 1.3379 - val_accuracy: 0.6395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7efb8310>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=256,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "#nn.add(Dropout(0.3, input_shape=(768,)))\n",
    "#nn.add(Dense(1024, input_dim= 768, activation=\"relu\")) # input_dim= 768\n",
    "#nn.add(Dropout(0.3))\n",
    "#nn.add(Dense(256, activation=\"relu\"))\n",
    "#nn.add(Dropout(0.3))\n",
    "nn.add(Dense(51, activation=\"softmax\")) #a completer\n",
    "\n",
    "nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 2s 307us/step - loss: 3.1275 - accuracy: 0.2024 - val_loss: 2.9550 - val_accuracy: 0.2316\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 1s 195us/step - loss: 2.8554 - accuracy: 0.2560 - val_loss: 2.7833 - val_accuracy: 0.2740\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 1s 202us/step - loss: 2.6956 - accuracy: 0.2969 - val_loss: 2.6617 - val_accuracy: 0.3381\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 1s 209us/step - loss: 2.5654 - accuracy: 0.3335 - val_loss: 2.5528 - val_accuracy: 0.3611\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 1s 204us/step - loss: 2.4514 - accuracy: 0.3666 - val_loss: 2.4508 - val_accuracy: 0.3867\n",
      "Epoch 6/30\n",
      "6422/6422 [==============================] - 1s 211us/step - loss: 2.3570 - accuracy: 0.3927 - val_loss: 2.3725 - val_accuracy: 0.4016\n",
      "Epoch 7/30\n",
      "6422/6422 [==============================] - 1s 205us/step - loss: 2.2736 - accuracy: 0.4123 - val_loss: 2.2970 - val_accuracy: 0.4209\n",
      "Epoch 8/30\n",
      "6422/6422 [==============================] - 1s 221us/step - loss: 2.1969 - accuracy: 0.4355 - val_loss: 2.2339 - val_accuracy: 0.4296\n",
      "Epoch 9/30\n",
      "6422/6422 [==============================] - 1s 211us/step - loss: 2.1308 - accuracy: 0.4497 - val_loss: 2.1820 - val_accuracy: 0.4651\n",
      "Epoch 10/30\n",
      "6422/6422 [==============================] - 1s 208us/step - loss: 2.0704 - accuracy: 0.4656 - val_loss: 2.1233 - val_accuracy: 0.4521\n",
      "Epoch 11/30\n",
      "6422/6422 [==============================] - 1s 214us/step - loss: 2.0157 - accuracy: 0.4827 - val_loss: 2.0784 - val_accuracy: 0.4689\n",
      "Epoch 12/30\n",
      "6422/6422 [==============================] - 1s 227us/step - loss: 1.9650 - accuracy: 0.4919 - val_loss: 2.0376 - val_accuracy: 0.4869\n",
      "Epoch 13/30\n",
      "6422/6422 [==============================] - 2s 236us/step - loss: 1.9181 - accuracy: 0.5028 - val_loss: 2.0026 - val_accuracy: 0.4907\n",
      "Epoch 14/30\n",
      "6422/6422 [==============================] - 2s 258us/step - loss: 1.8734 - accuracy: 0.5121 - val_loss: 1.9627 - val_accuracy: 0.5212\n",
      "Epoch 15/30\n",
      "6422/6422 [==============================] - 1s 208us/step - loss: 1.8328 - accuracy: 0.5246 - val_loss: 1.9314 - val_accuracy: 0.5212\n",
      "Epoch 16/30\n",
      "6422/6422 [==============================] - 1s 214us/step - loss: 1.7950 - accuracy: 0.5353 - val_loss: 1.9040 - val_accuracy: 0.5305\n",
      "Epoch 17/30\n",
      "6422/6422 [==============================] - 1s 223us/step - loss: 1.7575 - accuracy: 0.5424 - val_loss: 1.8759 - val_accuracy: 0.5268\n",
      "Epoch 18/30\n",
      "6422/6422 [==============================] - 2s 234us/step - loss: 1.7275 - accuracy: 0.5509 - val_loss: 1.8482 - val_accuracy: 0.5361\n",
      "Epoch 19/30\n",
      "6422/6422 [==============================] - 1s 212us/step - loss: 1.6951 - accuracy: 0.5568 - val_loss: 1.8172 - val_accuracy: 0.5336\n",
      "Epoch 20/30\n",
      "6422/6422 [==============================] - 1s 212us/step - loss: 1.6642 - accuracy: 0.5649 - val_loss: 1.7909 - val_accuracy: 0.5399\n",
      "Epoch 21/30\n",
      "6422/6422 [==============================] - 1s 216us/step - loss: 1.6374 - accuracy: 0.5779 - val_loss: 1.7716 - val_accuracy: 0.5455\n",
      "Epoch 22/30\n",
      "6422/6422 [==============================] - 1s 215us/step - loss: 1.6132 - accuracy: 0.5789 - val_loss: 1.7569 - val_accuracy: 0.5504\n",
      "Epoch 23/30\n",
      "6422/6422 [==============================] - 1s 221us/step - loss: 1.5867 - accuracy: 0.5881 - val_loss: 1.7241 - val_accuracy: 0.5654\n",
      "Epoch 24/30\n",
      "6422/6422 [==============================] - 1s 224us/step - loss: 1.5639 - accuracy: 0.5861 - val_loss: 1.7159 - val_accuracy: 0.5672\n",
      "Epoch 25/30\n",
      "6422/6422 [==============================] - 1s 213us/step - loss: 1.5420 - accuracy: 0.5958 - val_loss: 1.6934 - val_accuracy: 0.5635\n",
      "Epoch 26/30\n",
      "6422/6422 [==============================] - 2s 240us/step - loss: 1.5179 - accuracy: 0.6054 - val_loss: 1.6768 - val_accuracy: 0.5704\n",
      "Epoch 27/30\n",
      "6422/6422 [==============================] - 1s 215us/step - loss: 1.4979 - accuracy: 0.6087 - val_loss: 1.6598 - val_accuracy: 0.5753\n",
      "Epoch 28/30\n",
      "6422/6422 [==============================] - 1s 214us/step - loss: 1.4762 - accuracy: 0.6169 - val_loss: 1.6478 - val_accuracy: 0.5641\n",
      "Epoch 29/30\n",
      "6422/6422 [==============================] - 1s 227us/step - loss: 1.4587 - accuracy: 0.6157 - val_loss: 1.6366 - val_accuracy: 0.5866\n",
      "Epoch 30/30\n",
      "6422/6422 [==============================] - 1s 214us/step - loss: 1.4433 - accuracy: 0.6230 - val_loss: 1.6187 - val_accuracy: 0.5890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a91129d50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "\n",
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=32,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/30\n",
      "6422/6422 [==============================] - 1s 116us/step - loss: 1.4203 - accuracy: 0.6310 - val_loss: 1.6071 - val_accuracy: 0.5841\n",
      "Epoch 2/30\n",
      "6422/6422 [==============================] - 1s 118us/step - loss: 1.4091 - accuracy: 0.6319 - val_loss: 1.6030 - val_accuracy: 0.5922\n",
      "Epoch 3/30\n",
      "6422/6422 [==============================] - 1s 120us/step - loss: 1.4009 - accuracy: 0.6313 - val_loss: 1.5972 - val_accuracy: 0.5872\n",
      "Epoch 4/30\n",
      "6422/6422 [==============================] - 1s 126us/step - loss: 1.3935 - accuracy: 0.6344 - val_loss: 1.5853 - val_accuracy: 0.5922\n",
      "Epoch 5/30\n",
      "6422/6422 [==============================] - 1s 131us/step - loss: 1.3857 - accuracy: 0.6391 - val_loss: 1.5803 - val_accuracy: 0.5897\n",
      "Epoch 6/30\n",
      "6422/6422 [==============================] - 1s 134us/step - loss: 1.3772 - accuracy: 0.6391 - val_loss: 1.5778 - val_accuracy: 0.5903\n",
      "Epoch 7/30\n",
      "6422/6422 [==============================] - 1s 126us/step - loss: 1.3674 - accuracy: 0.6403 - val_loss: 1.5675 - val_accuracy: 0.5990\n",
      "Epoch 8/30\n",
      "6422/6422 [==============================] - 1s 128us/step - loss: 1.3590 - accuracy: 0.6394 - val_loss: 1.5616 - val_accuracy: 0.5990\n",
      "Epoch 9/30\n",
      "6422/6422 [==============================] - 1s 134us/step - loss: 1.3506 - accuracy: 0.6451 - val_loss: 1.5574 - val_accuracy: 0.5965\n",
      "Epoch 10/30\n",
      "6422/6422 [==============================] - 1s 129us/step - loss: 1.3434 - accuracy: 0.6454 - val_loss: 1.5523 - val_accuracy: 0.6021\n",
      "Epoch 11/30\n",
      "6422/6422 [==============================] - 1s 137us/step - loss: 1.3343 - accuracy: 0.6476 - val_loss: 1.5426 - val_accuracy: 0.5971\n",
      "Epoch 12/30\n",
      "6422/6422 [==============================] - 1s 133us/step - loss: 1.3263 - accuracy: 0.6487 - val_loss: 1.5376 - val_accuracy: 0.5984\n",
      "Epoch 13/30\n",
      "6422/6422 [==============================] - 1s 142us/step - loss: 1.3195 - accuracy: 0.6534 - val_loss: 1.5341 - val_accuracy: 0.6059\n",
      "Epoch 14/30\n",
      "6422/6422 [==============================] - 1s 129us/step - loss: 1.3113 - accuracy: 0.6546 - val_loss: 1.5287 - val_accuracy: 0.6065\n",
      "Epoch 15/30\n",
      "6422/6422 [==============================] - 1s 153us/step - loss: 1.3013 - accuracy: 0.6596 - val_loss: 1.5235 - val_accuracy: 0.6027\n",
      "Epoch 16/30\n",
      "6422/6422 [==============================] - 1s 130us/step - loss: 1.2941 - accuracy: 0.6570 - val_loss: 1.5149 - val_accuracy: 0.6052\n",
      "Epoch 17/30\n",
      "6422/6422 [==============================] - 1s 131us/step - loss: 1.2858 - accuracy: 0.6593 - val_loss: 1.5117 - val_accuracy: 0.6096\n",
      "Epoch 18/30\n",
      "6422/6422 [==============================] - 1s 140us/step - loss: 1.2791 - accuracy: 0.6607 - val_loss: 1.5035 - val_accuracy: 0.6108\n",
      "Epoch 19/30\n",
      "6422/6422 [==============================] - 1s 134us/step - loss: 1.2721 - accuracy: 0.6630 - val_loss: 1.4963 - val_accuracy: 0.6090\n",
      "Epoch 20/30\n",
      "6422/6422 [==============================] - 1s 130us/step - loss: 1.2635 - accuracy: 0.6679 - val_loss: 1.4903 - val_accuracy: 0.6121\n",
      "Epoch 21/30\n",
      "6422/6422 [==============================] - 1s 135us/step - loss: 1.2567 - accuracy: 0.6699 - val_loss: 1.4892 - val_accuracy: 0.6152\n",
      "Epoch 22/30\n",
      "6422/6422 [==============================] - 1s 137us/step - loss: 1.2486 - accuracy: 0.6693 - val_loss: 1.4842 - val_accuracy: 0.6139\n",
      "Epoch 23/30\n",
      "6422/6422 [==============================] - 1s 157us/step - loss: 1.2428 - accuracy: 0.6699 - val_loss: 1.4778 - val_accuracy: 0.6096\n",
      "Epoch 24/30\n",
      "6422/6422 [==============================] - 1s 141us/step - loss: 1.2342 - accuracy: 0.6690 - val_loss: 1.4696 - val_accuracy: 0.6183\n",
      "Epoch 25/30\n",
      "6422/6422 [==============================] - 1s 127us/step - loss: 1.2280 - accuracy: 0.6714 - val_loss: 1.4663 - val_accuracy: 0.6152\n",
      "Epoch 26/30\n",
      "6422/6422 [==============================] - 1s 135us/step - loss: 1.2205 - accuracy: 0.6747 - val_loss: 1.4649 - val_accuracy: 0.6189\n",
      "Epoch 27/30\n",
      "6422/6422 [==============================] - 1s 130us/step - loss: 1.2145 - accuracy: 0.6770 - val_loss: 1.4546 - val_accuracy: 0.6196\n",
      "Epoch 28/30\n",
      "6422/6422 [==============================] - 1s 133us/step - loss: 1.2070 - accuracy: 0.6789 - val_loss: 1.4522 - val_accuracy: 0.6220\n",
      "Epoch 29/30\n",
      "6422/6422 [==============================] - 1s 133us/step - loss: 1.2007 - accuracy: 0.6809 - val_loss: 1.4466 - val_accuracy: 0.6183\n",
      "Epoch 30/30\n",
      "6422/6422 [==============================] - 1s 127us/step - loss: 1.1945 - accuracy: 0.6822 - val_loss: 1.4402 - val_accuracy: 0.6152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7f0987d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=30, batch_size=64,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/10\n",
      "6422/6422 [==============================] - 0s 30us/step - loss: 1.1622 - accuracy: 0.6926 - val_loss: 1.4294 - val_accuracy: 0.6214\n",
      "Epoch 2/10\n",
      "6422/6422 [==============================] - 0s 31us/step - loss: 1.1627 - accuracy: 0.6937 - val_loss: 1.4293 - val_accuracy: 0.6208\n",
      "Epoch 3/10\n",
      "6422/6422 [==============================] - 0s 33us/step - loss: 1.1630 - accuracy: 0.6931 - val_loss: 1.4292 - val_accuracy: 0.6189\n",
      "Epoch 4/10\n",
      "6422/6422 [==============================] - 0s 32us/step - loss: 1.1628 - accuracy: 0.6932 - val_loss: 1.4287 - val_accuracy: 0.6177\n",
      "Epoch 5/10\n",
      "6422/6422 [==============================] - 0s 29us/step - loss: 1.1621 - accuracy: 0.6922 - val_loss: 1.4281 - val_accuracy: 0.6183\n",
      "Epoch 6/10\n",
      "6422/6422 [==============================] - 0s 30us/step - loss: 1.1613 - accuracy: 0.6923 - val_loss: 1.4277 - val_accuracy: 0.6189\n",
      "Epoch 7/10\n",
      "6422/6422 [==============================] - 0s 33us/step - loss: 1.1607 - accuracy: 0.6900 - val_loss: 1.4275 - val_accuracy: 0.6214\n",
      "Epoch 8/10\n",
      "6422/6422 [==============================] - 0s 30us/step - loss: 1.1602 - accuracy: 0.6900 - val_loss: 1.4275 - val_accuracy: 0.6202\n",
      "Epoch 9/10\n",
      "6422/6422 [==============================] - 0s 31us/step - loss: 1.1598 - accuracy: 0.6881 - val_loss: 1.4274 - val_accuracy: 0.6196\n",
      "Epoch 10/10\n",
      "6422/6422 [==============================] - 0s 30us/step - loss: 1.1596 - accuracy: 0.6881 - val_loss: 1.4270 - val_accuracy: 0.6202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7f1092d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(X_train), y_train, epochs=10, batch_size=2048,\n",
    "       validation_data=(np.array(X_valid), y_valid), shuffle=True) #, callbacks=[es]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yohannlefaou/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/yohannlefaou/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "export_X_train, export_X_test, export_y_train, export_y_test = train_test_split(train,\n",
    "                                                                                labels[\"intention\"].values,\n",
    "                                                                                test_size=0.2, \n",
    "                                                                                random_state=2019)\n",
    "\n",
    "export_X_train[\"intention\"] = export_y_train\n",
    "export_X_test[\"intention\"] = export_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_X_train.to_csv(\"data/train.tsv\", sep=\"\\t\", index=False)\n",
    "export_X_train.to_csv(\"data/test.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv(path_data +\"input_test_b1Yip6O.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.to_csv(\"data/dev.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
